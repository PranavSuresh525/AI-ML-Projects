{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKo/UgOcPOa3BRAAr7txTR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PranavSuresh525/AI-ML-Projects/blob/main/AI_Integration_in_Finance/Finance_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "_aBQwkq0Bf86"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U --no-warn-conflicts \\\n",
        "    langchain-huggingface \\\n",
        "    langchain-google-genai \\\n",
        "    langgraph \\\n",
        "    yfinance \\\n",
        "    gnews \\\n",
        "    transformers \\\n",
        "    accelerate \\\n",
        "    duckduckgo-search \\\n",
        "    langchain-text-splitters \\\n",
        "    langchain-chroma \\\n",
        "    langchain-community \\\n",
        "    ddgs\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import operator\n",
        "from datetime import datetime, timedelta\n",
        "from typing import TypedDict, List, Annotated, Dict, Any, Optional\n",
        "import yfinance as yf\n",
        "from gnews import GNews\n",
        "from transformers import pipeline\n",
        "from langchain_huggingface import HuggingFacePipeline, HuggingFaceEmbeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "from langchain_core.messages import HumanMessage, BaseMessage\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.documents import Document\n",
        "from langgraph.graph import StateGraph, END, START\n",
        "from IPython.display import HTML, Markdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## the local llm whixh avoids unecessary calls from gemini as there is a API limit\n",
        "local_pipe = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\", max_new_tokens=256, device_map=\"auto\")\n",
        "local_llm = HuggingFacePipeline(pipeline=local_pipe)\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDSAtgeZUOp2o1D2s_XeP-OY5Bn7Fy-LL0\"\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    temperature=0.2,\n",
        "    google_api_key=os.environ[\"GOOGLE_API_KEY\"]\n",
        ")\n",
        "# WEB SEARCH: Used by the local node to find tickers\n",
        "search_tool = DuckDuckGoSearchRun()\n",
        "_ticker_cache={}"
      ],
      "metadata": {
        "id": "sByPkSlVF_nX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe995462-12b6-40cd-f810-d47f049e8f59"
      },
      "execution_count": 346,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def smart_llm_invoke(prompt):\n",
        "  \"\"\"Try Gemini first, fallback to local LLM if it fails\"\"\"\n",
        "  try:\n",
        "      response = smart_llm_invoke([HumanMessage(content=prompt)])\n",
        "      return response.content.strip()\n",
        "  except Exception as e:\n",
        "      print(f\"Using Local llm...\")\n",
        "      response = local_llm.invoke(prompt)  # Remove the [HumanMessage(...)] wrapper\n",
        "      return response.strip()"
      ],
      "metadata": {
        "id": "1Eri27MgklVg"
      },
      "execution_count": 347,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a basic function to get all the info related to a stock\n",
        "def get_stock_price(ticker: str):\n",
        "  try:\n",
        "    stock = yf.Ticker(ticker)\n",
        "    info = stock.info\n",
        "    history = stock.history(period='1y')\n",
        "\n",
        "    if not info or not info.get('symbol') or history.empty:\n",
        "      return {\"error\": f\"No data found or invalid ticker for {ticker}\"}\n",
        "\n",
        "    return{\n",
        "            'ticker': ticker,\n",
        "            'current_price': info.get('currentPrice', 0),\n",
        "            'previous_close': info.get('previousClose', 0),\n",
        "            'day_high': info.get('dayHigh', 0),\n",
        "            'day_low': info.get('dayLow', 0),\n",
        "            'volume': info.get('volume', 0),\n",
        "            'market_cap': info.get('marketCap', 0),\n",
        "            'company_name': info.get('longName', ticker),\n",
        "            'pe_ratio': info.get('trailingPE', 0),\n",
        "            'dividend_yield': info.get('dividendYield', 0),\n",
        "            'target_mean_price': info.get('targetMeanPrice', 0),\n",
        "            'recommendation_key': info.get('recommendationKey', 'N/A'),\n",
        "            '50_day_average': history['Close'].rolling(window=50).mean().iloc[-1] if len(history) >= 50 else 0,\n",
        "            '200_day_average': history['Close'].rolling(window=200).mean().iloc[-1] if len(history) >= 200 else 0,\n",
        "            'price_history': history['Close'].tail(30).to_list()\n",
        "        }\n",
        "  except Exception as e:\n",
        "        return {\"error\": f\"Failed to fetch data for {ticker}: {str(e)}\"}"
      ],
      "metadata": {
        "id": "V19ta-92QLfm"
      },
      "execution_count": 348,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a function which accesses a pandas data frame and gets the latest stock price of the company-'item' here\n",
        "def get_recent_data(df, items):\n",
        "  if df.empty:\n",
        "    return {}\n",
        "  recent_data={}\n",
        "  for item in items:\n",
        "    try:\n",
        "      if item in df.index:\n",
        "          value = df.loc[item].iloc[0]\n",
        "          recent_data[item] = float(value) if value is not None else 0\n",
        "      else:\n",
        "          recent_data[item] = 0\n",
        "    except:\n",
        "      recent_data[item] = 0\n"
      ],
      "metadata": {
        "id": "Q6rMmwMGSldA"
      },
      "execution_count": 349,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a function which basically gets the latest info (listed below) from yahoo finance, uses the period here to know how long to look for\n",
        "def fetch_financial_statements(ticker: str, period: str)->dict:\n",
        "  try:\n",
        "    stock=yf.Ticker(ticker)\n",
        "    if not stock.info or not stock.info.get('symbol'):\n",
        "      return {'error': f'Invalid or no data for ticker {ticker}'}\n",
        "\n",
        "    if period=='quaterly':\n",
        "      balance_sheet=stock.quarterly_balance_sheet\n",
        "      income_statement=stock.quarterly_income_stmt\n",
        "      cash_flow=stock.quarterly_cashflow\n",
        "    else:\n",
        "      balance_sheet=stock.balance_sheet\n",
        "      income_statement=stock.income_stmt\n",
        "      cash_flow=stock.cashflow\n",
        "    return{\n",
        "        'balance_sheet': get_recent_data(balance_sheet, ['Total Cash', 'Total Debt']),\n",
        "        'income_statement': get_recent_data(income_statement, ['Total Revenue', 'Gross Profit']),\n",
        "        'cash_flow': get_recent_data(cash_flow, ['Net Cash Flow']),\n",
        "        'period': period\n",
        "    }\n",
        "  except Exception as e:\n",
        "    return {\"error\": f\"Failed to fetch data for {ticker}: {str(e)}\"}"
      ],
      "metadata": {
        "id": "v8_nylfNUsdk"
      },
      "execution_count": 350,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a simple validate function that cross checks with yf to see of the ticker exist\n",
        "def validate_ticker(potential_ticker: str):\n",
        "  try:\n",
        "    stock = yf.Ticker(potential_ticker)\n",
        "    info = stock.info\n",
        "    if info and 'symbol' in info and info.get('symbol'):\n",
        "      return info['symbol']\n",
        "    return None\n",
        "  except Exception as e:\n",
        "    return None"
      ],
      "metadata": {
        "id": "yEt8fO7LXq2s"
      },
      "execution_count": 351,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sentiment(text: str):\n",
        "    if not text:\n",
        "        return 0.0\n",
        "\n",
        "    prompt = f\"\"\"Analyze the sentiment of this financial news text.\n",
        "    Return ONLY a number between -1 (very negative) and 1 (very positive).\n",
        "\n",
        "    Text: {text}\n",
        "    sentiment:\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = smart_llm_invoke([HumanMessage(content=prompt)])\n",
        "        sentiment_score = float(response.strip())\n",
        "        return max(-1, min(1, sentiment_score))\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Fallback to keyword-based analysis\n",
        "    positive_words = [\n",
        "        'gain', 'gains', 'up', 'rise', 'surge', 'rally', 'jump', 'soar',\n",
        "        'climb', 'boost', 'profit', 'growth', 'outperform', 'beat', 'strong',\n",
        "        'bullish', 'optimistic', 'confidence', 'upgrade', 'buy', 'positive'\n",
        "    ]\n",
        "\n",
        "    negative_words = [\n",
        "        'loss', 'down', 'drop', 'fall', 'decline', 'plunge', 'crash',\n",
        "        'tumble', 'slump', 'miss', 'disappoint', 'weak', 'bearish',\n",
        "        'pessimistic', 'concern', 'worry', 'fear', 'downgrade', 'sell'\n",
        "    ]\n",
        "\n",
        "    intensifiers = ['very', 'extremely', 'highly', 'significantly']\n",
        "    negations = ['not', 'no', 'never', \"don't\", \"doesn't\", \"won't\"]\n",
        "\n",
        "    words = text.lower().split()\n",
        "    positive_count = 0\n",
        "    negative_count = 0\n",
        "\n",
        "    for i, word in enumerate(words):\n",
        "        # Check for intensifiers\n",
        "        multiplier = 1.5 if i > 0 and words[i-1] in intensifiers else 1.0\n",
        "\n",
        "        # Check for negations (flip sentiment)\n",
        "        is_negated = i > 0 and words[i-1] in negations\n",
        "\n",
        "        if word in positive_words:\n",
        "            if is_negated:\n",
        "                negative_count += multiplier\n",
        "            else:\n",
        "                positive_count += multiplier\n",
        "        elif word in negative_words:\n",
        "            if is_negated:\n",
        "                positive_count += multiplier\n",
        "            else:\n",
        "                negative_count += multiplier\n",
        "\n",
        "    if positive_count + negative_count == 0:\n",
        "        return 0.0\n",
        "\n",
        "    return (positive_count - negative_count) / (positive_count + negative_count)"
      ],
      "metadata": {
        "id": "IYpfw7IE6DpO"
      },
      "execution_count": 352,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the heart of the model that connects the model through a RAG pipeline\n",
        "class NewsRAG:\n",
        "  def __init__(self, embedding_model=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
        "    self.embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=embedding_model\n",
        "    )\n",
        "    self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=500,\n",
        "        chunk_overlap=50\n",
        "    )\n",
        "    self.vectorstore = None\n",
        "  def index_news(self, news_articles: List[Dict]):\n",
        "    \"\"\"\n",
        "    news_articles example:\n",
        "    {\n",
        "        \"title\": \"...\",\n",
        "        \"content\": \"...\",\n",
        "        \"link\": \"...\",\n",
        "        \"date\": \"...\",\n",
        "        \"source\": \"...\"\n",
        "    }\n",
        "    \"\"\"\n",
        "    documents = []\n",
        "    for article in news_articles:\n",
        "        content = article.get(\"content\", \"\") or article.get(\"title\", \"\")\n",
        "        header=f\"Source: {article.get('source')}| Date: {article.get('date')}\"\n",
        "        metadata = {\n",
        "            \"title\": article.get(\"title\", \"\"),\n",
        "            \"link\": article.get(\"link\", \"\"),\n",
        "            \"date\": article.get(\"date\", \"\"),\n",
        "            \"source\": article.get(\"source\", \"\")\n",
        "        }\n",
        "\n",
        "        documents.append(\n",
        "            Document(\n",
        "                page_content=content,\n",
        "                metadata=metadata\n",
        "            )\n",
        "        )\n",
        "    if documents:\n",
        "      splits = self.text_splitter.split_documents(documents)\n",
        "      self.vectorstore = Chroma.from_documents(\n",
        "          documents=splits,\n",
        "          embedding=self.embeddings\n",
        "      )\n",
        "\n",
        "  def retrieve_context(self, query: str, k: int = 5) -> List[Dict]:\n",
        "    if self.vectorstore is None:\n",
        "      return []\n",
        "    docs = self.vectorstore.similarity_search(query, k=k)\n",
        "    return self.__distill_context(query, docs)\n",
        "\n",
        "  def __distill_context(self, query: str, docs: List[Document]) -> List[Dict]:\n",
        "    raw_text=\"\\n--\\n\".join([d.page_content for d in docs])\n",
        "    distil_prompts=f\"\"\"\n",
        "        Extract ONLY the facts from the news snippets below that directly answer the query: \"{query}\"\n",
        "        If the snippets are irrelevant, return \"No relevant news found.\"\n",
        "\n",
        "        Snippets:\n",
        "        {raw_text}\n",
        "\n",
        "        Key Facts:\n",
        "        \"\"\"\n",
        "    response = smart_llm_invoke(distil_prompts)\n",
        "    return response.strip().split(\"\\n--\\n\")"
      ],
      "metadata": {
        "id": "TzDfoyru7TAy"
      },
      "execution_count": 353,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    query: str\n",
        "    ticker: str\n",
        "    intent: str\n",
        "    price_data: dict\n",
        "    financial_data: dict\n",
        "    news_articles: list  # Remove Annotated\n",
        "    news_context: list   # Remove Annotated\n",
        "    sentiment_score: float\n",
        "    analysis: str\n",
        "    recommendation: str\n",
        "    messages: list       # Remove Annotated"
      ],
      "metadata": {
        "id": "03-EXbKtcsyN"
      },
      "execution_count": 354,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def intent_classifier(state: AgentState):\n",
        "    query = state['query']\n",
        "    query_lower = query.lower()\n",
        "\n",
        "    # Check for specific milestone questions (like \"when did X hit Y\")\n",
        "    if any(word in query_lower for word in ['when did', 'when was']) and any(word in query_lower for word in ['hit', 'reach', 'achieve', 'cross']):\n",
        "        intent = 'milestone_query'\n",
        "    elif any(word in query_lower for word in ['why', 'reason', 'cause']):\n",
        "        intent = 'reason_query'\n",
        "    elif any(word in query_lower for word in ['when', 'trend', 'history']):\n",
        "        intent = 'trend_analysis'\n",
        "    elif any(word in query_lower for word in ['compare', 'vs', 'versus']):\n",
        "        intent = 'comparison'\n",
        "    elif any(word in query_lower for word in ['price', 'cost', 'trading at']):\n",
        "        intent = 'price_query'\n",
        "    else:\n",
        "        intent = 'general'\n",
        "\n",
        "    state['intent'] = intent\n",
        "    state['messages'].append(f\"[Intent Classifier] Intent: {intent}\")\n",
        "    return state"
      ],
      "metadata": {
        "id": "-2CCz_-_gIgc"
      },
      "execution_count": 355,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ticker_extractor(state: AgentState):\n",
        "  query=state['query']\n",
        "  ticker_pattern= r'\\b[A-Z]{1,5}\\b'\n",
        "  matches=re.findall(ticker_pattern, query)\n",
        "\n",
        "  for match in matches:\n",
        "    if validate_ticker(match):\n",
        "      state['ticker']=match\n",
        "      state['messages'].append(f\"[Ticker Extractor] Ticker: {match}\")\n",
        "      return state\n",
        "\n",
        "  prompt = f\"\"\"Extract the company name or stock ticker from this query.\n",
        "    Return ONLY the ticker symbol (e.g., AAPL, MSFT) or company name.\n",
        "    Query: {query}\n",
        "    Answer:\"\"\"\n",
        "\n",
        "  response=smart_llm_invoke([HumanMessage(content=prompt)])\n",
        "  potential_ticker = response.strip().upper()\n",
        "\n",
        "  if len(potential_ticker) > 5:\n",
        "    search_query = f\"{potential_ticker} stock ticker symbol\"\n",
        "    search_result = search_tool.run(search_query)\n",
        "    ticker_match = re.search(r'\\(([A-Z]{1,5})\\)', search_result)\n",
        "    if ticker_match:\n",
        "        potential_ticker = ticker_match.group(1)\n",
        "\n",
        "  ticker = validate_ticker(potential_ticker)\n",
        "  if ticker:\n",
        "    state['ticker']=ticker\n",
        "    state['messages'].append(f\"[Ticker Extractor] Ticker: {ticker}\")\n",
        "  else:\n",
        "    state['ticker'] = \"\"\n",
        "    state['messages'].append(f\"[Ticker Extractor] Could not find valid ticker\")\n",
        "  return state"
      ],
      "metadata": {
        "id": "_23gH8FVAPfg"
      },
      "execution_count": 356,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def price_fetcher(state: AgentState):\n",
        "  ticker=state['ticker']\n",
        "  if ticker:\n",
        "    price_data=get_stock_price(ticker)\n",
        "    state['price_data']=price_data\n",
        "    state['messages'].append(f\"[Price Fetcher] Price Data: {price_data}\")\n",
        "  else:\n",
        "    state['price_data']={}\n",
        "    state['messages'].append(f\"[Price Fetcher] No price data found\")\n",
        "  return state"
      ],
      "metadata": {
        "id": "cfX7ygAEcyub"
      },
      "execution_count": 357,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def financial_fetcher(state: AgentState):\n",
        "  ticker=state['ticker']\n",
        "  intent=state['intent']\n",
        "  if intent in ['general', 'comparison'] and ticker:\n",
        "    financial_data=fetch_financial_statements(ticker, 'annual')\n",
        "    state['financial_data']=financial_data\n",
        "    state['messages'].append(f\"[Financial Fetcher] Financial Data: {financial_data}\")\n",
        "  else:\n",
        "    state['financial_data']={}\n",
        "    state['messages'].append(f\"[Financial Fetcher] No financial data found\")\n",
        "  return state"
      ],
      "metadata": {
        "id": "A6JAhSvddVNI"
      },
      "execution_count": 358,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def news_fetcher(state: AgentState):\n",
        "    ticker = state['ticker']\n",
        "    if not ticker:\n",
        "        return state\n",
        "\n",
        "    try:\n",
        "        company_name = state['price_data'].get('company_name', ticker)\n",
        "        google_news = GNews(language='en', period='7d', max_results=10)\n",
        "        news = google_news.get_news(f\"{company_name} stock\")\n",
        "\n",
        "        articles = []\n",
        "        for item in news:\n",
        "            articles.append({\n",
        "                'title': item.get('title', ''),\n",
        "                'content': item.get('description', ''),  # Changed from 'desc'\n",
        "                'link': item.get('url', ''),\n",
        "                'date': item.get('published date', ''),\n",
        "                'source': item.get('publisher', {}).get('title', '') if isinstance(item.get('publisher'), dict) else item.get('publisher', '')\n",
        "            })\n",
        "\n",
        "        state['news_articles'] = articles\n",
        "        state['messages'].append(f\"[News Fetcher] Found {len(articles)} articles\")\n",
        "\n",
        "    except Exception as e:\n",
        "        state['news_articles'] = []\n",
        "        state['messages'].append(f\"[News Fetcher] Error: {str(e)}\")\n",
        "\n",
        "    return state"
      ],
      "metadata": {
        "id": "umQuooOqd3ix"
      },
      "execution_count": 359,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def news_analyzer(state: AgentState):\n",
        "  news_articles=state['news_articles']\n",
        "  if not news_articles:\n",
        "    state['news_context']=[]\n",
        "    state['messages'].append(f\"[News Analyzer] No news articles to analyze\")\n",
        "    return state\n",
        "  rag=NewsRAG()\n",
        "  rag.index_news(news_articles)\n",
        "\n",
        "  context=state['news_context']\n",
        "  if not context:\n",
        "    context=rag.retrieve_context(state['query'])\n",
        "  state['news_context']=context\n",
        "\n",
        "  sentiment=analyze_sentiment(\"\\n--\\n\".join(context))\n",
        "  state['sentiment_score']=sentiment\n",
        "\n",
        "  state['messages'].append(f\"[News Analyzer] Sentiment Score: {sentiment}\")\n",
        "  return state"
      ],
      "metadata": {
        "id": "LE8QITsWfGss"
      },
      "execution_count": 360,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response_generator(state: AgentState):\n",
        "    \"\"\"Generate final response based on all gathered data\"\"\"\n",
        "    query = state['query']\n",
        "    ticker = state['ticker']\n",
        "    intent = state['intent']\n",
        "    price_data = state['price_data']\n",
        "    news_context = state['news_context']\n",
        "    news_articles = state['news_articles']\n",
        "    sentiment = state['sentiment_score']\n",
        "\n",
        "    # Build context for LLM\n",
        "    context_parts = []\n",
        "\n",
        "    if price_data and 'error' not in price_data:\n",
        "        context_parts.append(f\"\"\"\n",
        "Stock Data for {ticker}:\n",
        "- Current Price: ${price_data.get('current_price', 0):.2f}\n",
        "- Previous Close: ${price_data.get('previous_close', 0):.2f}\n",
        "- Day High/Low: ${price_data.get('day_high', 0):.2f} / ${price_data.get('day_low', 0):.2f}\n",
        "- 50-day Average: ${price_data.get('50_day_average', 0):.2f}\n",
        "- Recommendation: {price_data.get('recommendation_key', 'N/A')}\n",
        "\"\"\")\n",
        "\n",
        "    if news_context:\n",
        "        context_parts.append(f\"Recent News Context:\\n\" + \"\\n\".join(news_context))\n",
        "\n",
        "    context_parts.append(f\"Overall Sentiment Score: {sentiment:.2f} (-1 = very negative, 1 = very positive)\")\n",
        "\n",
        "    full_context = \"\\n\\n\".join(context_parts)\n",
        "\n",
        "    # Create prompt based on intent\n",
        "    if intent == 'reason_query':\n",
        "        prompt = f\"\"\"You are a financial analyst. Based on the data below, explain WHY {ticker} stock moved recently.\n",
        "\n",
        "{full_context}\n",
        "\n",
        "User Question: {query}\n",
        "\n",
        "Instructions:\n",
        "- Write in clear, professional prose (not bullet points)\n",
        "- Cite specific events or news\n",
        "- Be concise (2-3 sentences max)\n",
        "- Do NOT copy/paste news headlines\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "    elif intent == 'trend_analysis':\n",
        "        prompt = f\"\"\"You are a financial analyst. Based on the data below, analyze WHEN and HOW {ticker} has been trending.\n",
        "\n",
        "{full_context}\n",
        "\n",
        "User Question: {query}\n",
        "\n",
        "Instructions:\n",
        "- Answer the specific timing question asked\n",
        "- Reference price movements and dates if available\n",
        "- Be concise (2-3 sentences max)\n",
        "- Write in clear prose, not headlines\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "    elif intent == 'price_query':\n",
        "        prompt = f\"\"\"Based on the stock data below, answer this price question about {ticker}.\n",
        "\n",
        "{full_context}\n",
        "\n",
        "User Question: {query}\n",
        "\n",
        "Instructions:\n",
        "- Give the specific price information requested\n",
        "- Be direct and accurate\n",
        "- Keep it brief (1-2 sentences)\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "    elif intent == 'milestone_query':\n",
        "      prompt = f\"\"\"Answer this question about {ticker} stock using the data below.\n",
        "\n",
        "Current market cap: ${price_data.get('market_cap', 0):,.0f}\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "News headlines:\n",
        "{chr(10).join([f\"- {a.get('title', '')}\" for a in news_articles[:5]])}\n",
        "\n",
        "Answer the question directly. If the milestone isn't mentioned in the news, say \"No recent news about this milestone.\"\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "    else:\n",
        "        prompt = f\"\"\"Based on the stock data and news below, answer this question about {ticker}.\n",
        "\n",
        "{full_context}\n",
        "\n",
        "User Question: {query}\n",
        "\n",
        "Instructions:\n",
        "- Provide a helpful, accurate response\n",
        "- Write in clear prose\n",
        "- Be concise\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "    # Get response from LLM\n",
        "    response_text = smart_llm_invoke(prompt)\n",
        "\n",
        "    # Add sources if news articles exist\n",
        "    if news_articles and len(news_articles) > 0:\n",
        "        response_text += \"\\n\\n**Sources:**\"\n",
        "        for i, article in enumerate(news_articles[:5], 1):\n",
        "            response_text += f\"\\n{i}. [{article.get('title', 'No title')}]({article.get('link', '#')}) - {article.get('source', 'Unknown')} ({article.get('date', 'No date')})\"\n",
        "\n",
        "    state['analysis'] = response_text\n",
        "\n",
        "    return state"
      ],
      "metadata": {
        "id": "BeNaONHsfoDE"
      },
      "execution_count": 361,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_workflow():\n",
        "    workflow = StateGraph(AgentState)\n",
        "\n",
        "\n",
        "    workflow.add_node(\"intent_classifier\", intent_classifier)\n",
        "    workflow.add_node(\"ticker_extractor\", ticker_extractor)\n",
        "    workflow.add_node(\"price_fetcher\", price_fetcher)\n",
        "    workflow.add_node(\"financial_fetcher\", financial_fetcher)\n",
        "    workflow.add_node(\"news_fetcher\", news_fetcher)\n",
        "    workflow.add_node(\"news_analyzer\", news_analyzer)\n",
        "    workflow.add_node(\"response_generator\", response_generator)\n",
        "\n",
        "    workflow.add_edge(START, \"intent_classifier\")\n",
        "    workflow.add_edge(\"intent_classifier\", \"ticker_extractor\")\n",
        "    workflow.add_edge(\"ticker_extractor\", \"price_fetcher\")\n",
        "    workflow.add_edge(\"price_fetcher\", \"financial_fetcher\")\n",
        "    workflow.add_edge(\"financial_fetcher\", \"news_fetcher\")\n",
        "    workflow.add_edge(\"news_fetcher\", \"news_analyzer\")\n",
        "    workflow.add_edge(\"news_analyzer\", \"response_generator\")\n",
        "    workflow.add_edge(\"response_generator\", END)\n",
        "\n",
        "    return workflow.compile()\n",
        "agent = build_workflow()"
      ],
      "metadata": {
        "id": "Yx1lErg_gZS8"
      },
      "execution_count": 362,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_stocks(user_query: str):\n",
        "    initial_state = {\n",
        "        'query': user_query,\n",
        "        'ticker': '',\n",
        "        'intent': '',\n",
        "        'price_data': {},\n",
        "        'financial_data': {},\n",
        "        'news_articles': [],  # Start empty\n",
        "        'news_context': [],\n",
        "        'sentiment_score': 0.0,\n",
        "        'analysis': '',\n",
        "        'recommendation': '',\n",
        "        'messages': []\n",
        "    }\n",
        "\n",
        "    result = agent.invoke(initial_state)\n",
        "\n",
        "    return {\n",
        "        'answer': result['analysis'],\n",
        "        'ticker': result['ticker'],\n",
        "        'sentiment': result['sentiment_score'],\n",
        "        'debug_messages': result['messages']\n",
        "    }"
      ],
      "metadata": {
        "id": "97yTJnkShTzb"
      },
      "execution_count": 363,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result1 = query_stocks(\"When did Microsoft go up?\" )\n",
        "print(f\"Query: When did Microsoft go up?\")\n",
        "print(f\"Answer: {result1['answer']}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4PLQwmohePK",
        "outputId": "e8be1495-3280-48af-cb5f-d425fd6ac1ce"
      },
      "execution_count": 364,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Local llm...\n",
            "Using Local llm...\n",
            "Using Local llm...\n",
            "Using Local llm...\n",
            "Using Local llm...\n",
            "Using Local llm...\n",
            "\n",
            "=== WORKFLOW DEBUG ===\n",
            "[Intent Classifier] Intent: trend_analysis\n",
            "[Ticker Extractor] Ticker: MSFT\n",
            "[Price Fetcher] Price Data: {'ticker': 'MSFT', 'current_price': 465.95, 'previous_close': 450.865, 'day_high': 471.1, 'day_low': 450.6, 'volume': 37533469, 'market_cap': 3463484014592, 'company_name': 'Microsoft Corporation', 'pe_ratio': 33.11656, 'dividend_yield': 0.78, 'target_mean_price': 617.8565, 'recommendation_key': 'strong_buy', '50_day_average': np.float64(480.8758209228516), '200_day_average': np.float64(482.8081169128418), 'price_history': [478.55999755859375, 483.4700012207031, 478.5299987792969, 474.82000732421875, 476.3900146484375, 476.1199951171875, 483.9800109863281, 485.9200134277344, 484.9200134277344, 486.8500061035156, 488.0199890136719, 487.7099914550781, 487.1000061035156, 487.4800109863281, 483.6199951171875, 472.94000244140625, 472.8500061035156, 478.510009765625, 483.4700012207031, 478.1099853515625, 479.2799987792969, 477.17999267578125, 470.6700134277344, 459.3800048828125, 456.6600036621094, 459.8599853515625, 454.5199890136719, 444.1099853515625, 451.1400146484375, 465.95001220703125]}\n",
            "[Financial Fetcher] No financial data found\n",
            "[News Fetcher] Found 10 articles\n",
            "[News Analyzer] Sentiment Score: -1\n",
            "======================\n",
            "\n",
            "[DEBUG] Ticker: MSFT\n",
            "[DEBUG] Price Data: 465.95\n",
            "[DEBUG] News Articles Found: 10\n",
            "[DEBUG] Sentiment: -1\n",
            "Query: When did Microsoft go up?\n",
            "Answer: Answer the specific timing question asked\n",
            "\n",
            "**Sources:**\n",
            "1. [Microsoft (MSFT) Traded Lower as Its Reported Azure Cloud Growth and Forward Guidance Fell Short of Expectations - Yahoo Finance](https://news.google.com/rss/articles/CBMiigFBVV95cUxOMU9aa25yNGNNUEJITXZwWVV6RFNXZy11dFNJT05KUTVkeEFXanpaLWx6Mzd2ekFCbXpkQktnWWhpVnI4N2d3S1ZkejV3by11RlJ6WkkxRDJ1VUkyRldjRDZSNnBham45UWRIcjJCckZ0NndQaGNlQXhrVnkwQm51YUlSNG5tZGcyWHc?oc=5&hl=en-US&gl=US&ceid=US:en) - Yahoo Finance (Tue, 20 Jan 2026 14:15:28 GMT)\n",
            "2. [Microsoft Stock To $350? - Forbes](https://news.google.com/rss/articles/CBMiiAFBVV95cUxQcmNlUVZTNzE3LWtIdUNRSy1VcFFSZVVGQWQ5c3dzV1lpUFZaRW5rT2Jac2tkQ1BkdzRZdVI2YmdyQV93bUp2dnhhSlByYUp4dmJsWE5iOFlIbEgtUVhOeHRTczdRTldmRUlIVFlRdVhnU051QThfNFIxRzVGZEVMS0VLREwxaDli?oc=5&hl=en-US&gl=US&ceid=US:en) - Forbes (Thu, 22 Jan 2026 13:23:05 GMT)\n",
            "3. [Microsoft: Something Doesn't Add Up (NASDAQ:MSFT) - Seeking Alpha](https://news.google.com/rss/articles/CBMif0FVX3lxTE5lM2o0dEpxQllyMU13WkxwRkJKNEl5WnI4b3k5YW1VT2I2N004dlE4V2hBZUdsMVZ6RTNwTXhHOXZqNTl2emtUZFBUMGFwQjNJd2RYU3VSQ21CcjJacTd3YW9GRTJaTTRfMVRZMHYtM29pd0duNTNaN1VGdVVoQjQ?oc=5&hl=en-US&gl=US&ceid=US:en) - Seeking Alpha (Mon, 19 Jan 2026 15:33:28 GMT)\n",
            "4. [OneAscent Financial Services LLC Has $6.73 Million Stock Holdings in Microsoft Corporation $MSFT - InsuranceNewsNet](https://news.google.com/rss/articles/CBMizAFBVV95cUxNTlpMZnI4TlFITTdUSkFkQkgwOGhUOWRwbTFDMllrR1o3TUt5YjYyTmEwUjI5LW5pVDd6SGwxZUpGa2NTYWRXbWRGZzZiclAwWTl1WDBxWHhCbXRaeUN2ajdJM0RKNHN4S1NQajNLcW5rMXFyRmlCNkpKODVnNzI0dlk2SnVJcjA5SlB2QU9HUmRwbXgwOXB1WXFJRDFRQTdkaGtNa0owam12RnFNc0FURHVHYkJDNWFIRkJrbTMxX2hyV2VZeF9oYTZJa3Y?oc=5&hl=en-US&gl=US&ceid=US:en) - InsuranceNewsNet (Sat, 24 Jan 2026 09:56:09 GMT)\n",
            "5. [Microsoft Corporation $MSFT Stock Position Reduced by Commonwealth Equity Services LLC - MarketBeat](https://news.google.com/rss/articles/CBMi3wFBVV95cUxQV2pjcTZ2ZlMwN3hNU3c0Ry05ZXlxdHFWdW5EOEtVY2owSFVzQk9WM2ZuT25qUkhCYTE3Y3BtdGU1VDlTUy1fcnpUR29HQXRhV01DRTNrMzBFeTdicHd6Rjhndk5nd1Q4OEVvWkpOeGN4Y3pmX2ljZE40WnRPM3dlYVQ5VXhYZWp2NE1nVUFzcEZBRktEUzhBTFlpZjhoM1lCQVZwOS1oMWxOSjdESjkwb29Bb05OX0Rjd2tzcEtpMjQ3eEc3M2lRNzZLc1U2LWt2THBKM1psNHJld3UzWHVV?oc=5&hl=en-US&gl=US&ceid=US:en) - MarketBeat (Wed, 21 Jan 2026 09:28:50 GMT)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}