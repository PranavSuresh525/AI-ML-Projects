{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBPddeJmSvg+/2wvK0PDIi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PranavSuresh525/AI-ML-Projects/blob/main/AI_Integration_in_Finance/Finance_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "_aBQwkq0Bf86"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U --no-warn-conflicts \\\n",
        "    langchain-huggingface \\\n",
        "    langchain-google-genai \\\n",
        "    langgraph \\\n",
        "    yfinance \\\n",
        "    transformers \\\n",
        "    accelerate \\\n",
        "    duckduckgo-search \\\n",
        "    langchain-text-splitters \\\n",
        "    langchain-chroma \\\n",
        "    langchain-community \\\n",
        "    ddgs\\\n",
        "    newsapi-python\n",
        "import numpy as np\n",
        "import requests\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "from newsapi import NewsApiClient\n",
        "import operator\n",
        "from datetime import datetime, timedelta\n",
        "from typing import TypedDict, List, Annotated, Dict, Any, Optional\n",
        "import yfinance as yf\n",
        "from transformers import pipeline\n",
        "from langchain_huggingface import HuggingFacePipeline, HuggingFaceEmbeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "from langchain_core.messages import HumanMessage, BaseMessage\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.documents import Document\n",
        "from langgraph.graph import StateGraph, END, START\n",
        "from IPython.display import HTML, Markdown\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## the local llm whixh avoids unecessary calls from gemini as there is a API limit\n",
        "local_pipe = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\", max_new_tokens=256, device_map=\"auto\")\n",
        "local_llm = HuggingFacePipeline(pipeline=local_pipe)\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_TOKEN')\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemma-3-12b-it\",\n",
        "    temperature=0.2,\n",
        "    google_api_key=os.environ[\"GOOGLE_API_KEY\"]\n",
        ")\n",
        "# WEB SEARCH: Used by the local node to find tickers\n",
        "search_tool = DuckDuckGoSearchRun()\n",
        "_ticker_cache={}"
      ],
      "metadata": {
        "id": "sByPkSlVF_nX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fa943a3-ad0f-4e3e-9ad8-35b02b5e4a8f"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def smart_llm_invoke(prompt):\n",
        "  #\"\"\"Try Gemini first, fallback to local LLM if it fails\"\"\"\n",
        "  try:\n",
        "      response = llm.invoke([HumanMessage(content=prompt)])\n",
        "      return response.content.strip()\n",
        "  except Exception as e:\n",
        "      print(f\"Error from Gemini: {e}\")\n",
        "      response = local_llm.invoke(prompt)  # Remove the [HumanMessage(...)] wrapper\n",
        "      return response.strip()"
      ],
      "metadata": {
        "id": "1Eri27MgklVg"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a basic function to get all the info related to a stock\n",
        "def get_stock_price(ticker: str):\n",
        "  try:\n",
        "    stock = yf.Ticker(ticker)\n",
        "    info = stock.info\n",
        "    history = stock.history(period='1y')\n",
        "\n",
        "    if not info or not info.get('symbol') or history.empty:\n",
        "      return {\"error\": f\"No data found or invalid ticker for {ticker}\"}\n",
        "\n",
        "    return{\n",
        "            'ticker': ticker,\n",
        "            'current_price': info.get('currentPrice', 0),\n",
        "            'previous_close': info.get('previousClose', 0),\n",
        "            'day_high': info.get('dayHigh', 0),\n",
        "            'day_low': info.get('dayLow', 0),\n",
        "            'volume': info.get('volume', 0),\n",
        "            'market_cap': info.get('marketCap', 0),\n",
        "            'company_name': info.get('longName', ticker),\n",
        "            'pe_ratio': info.get('trailingPE', 0),\n",
        "            'dividend_yield': info.get('dividendYield', 0),\n",
        "            'target_mean_price': info.get('targetMeanPrice', 0),\n",
        "            'recommendation_key': info.get('recommendationKey', 'N/A'),\n",
        "            '50_day_average': history['Close'].rolling(window=50).mean().iloc[-1] if len(history) >= 50 else 0,\n",
        "            '200_day_average': history['Close'].rolling(window=200).mean().iloc[-1] if len(history) >= 200 else 0,\n",
        "            'price_history': history['Close'].tail(30).to_list()\n",
        "        }\n",
        "  except Exception as e:\n",
        "        return {\"error\": f\"Failed to fetch data for {ticker}: {str(e)}\"}"
      ],
      "metadata": {
        "id": "V19ta-92QLfm"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a function which accesses a pandas data frame and gets the latest stock price of the company-'item' here\n",
        "def get_recent_data(df, items):\n",
        "  if df.empty:\n",
        "    return {}\n",
        "  recent_data={}\n",
        "  for item in items:\n",
        "    try:\n",
        "      if item in df.index:\n",
        "          value = df.loc[item].iloc[0]\n",
        "          recent_data[item] = float(value) if value is not None else 0\n",
        "      else:\n",
        "          recent_data[item] = 0\n",
        "    except:\n",
        "      recent_data[item] = 0\n"
      ],
      "metadata": {
        "id": "Q6rMmwMGSldA"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a function which basically gets the latest info (listed below) from yahoo finance, uses the period here to know how long to look for\n",
        "def fetch_financial_statements(ticker: str, period: str)->dict:\n",
        "  try:\n",
        "    stock=yf.Ticker(ticker)\n",
        "    if not stock.info or not stock.info.get('symbol'):\n",
        "      return {'error': f'Invalid or no data for ticker {ticker}'}\n",
        "\n",
        "    if period=='quaterly':\n",
        "      balance_sheet=stock.quarterly_balance_sheet\n",
        "      income_statement=stock.quarterly_income_stmt\n",
        "      cash_flow=stock.quarterly_cashflow\n",
        "    else:\n",
        "      balance_sheet=stock.balance_sheet\n",
        "      income_statement=stock.income_stmt\n",
        "      cash_flow=stock.cashflow\n",
        "    return{\n",
        "        'balance_sheet': get_recent_data(balance_sheet, ['Total Cash', 'Total Debt']),\n",
        "        'income_statement': get_recent_data(income_statement, ['Total Revenue', 'Gross Profit']),\n",
        "        'cash_flow': get_recent_data(cash_flow, ['Net Cash Flow']),\n",
        "        'period': period\n",
        "    }\n",
        "  except Exception as e:\n",
        "    return {\"error\": f\"Failed to fetch data for {ticker}: {str(e)}\"}"
      ],
      "metadata": {
        "id": "v8_nylfNUsdk"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a simple validate function that cross checks with yf to see of the ticker exist\n",
        "def validate_ticker(potential_ticker: str):\n",
        "  try:\n",
        "    stock = yf.Ticker(potential_ticker)\n",
        "    info = stock.info\n",
        "    if info and 'symbol' in info and info.get('symbol'):\n",
        "      return info['symbol']\n",
        "    return None\n",
        "  except Exception as e:\n",
        "    return None"
      ],
      "metadata": {
        "id": "yEt8fO7LXq2s"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sentiment(text: str):\n",
        "    if not text:\n",
        "        return 0.0\n",
        "\n",
        "    prompt = f\"\"\"Analyze the sentiment of this financial news text.\n",
        "    Return ONLY a number between -1 (very negative) and 1 (very positive).\n",
        "\n",
        "    Text: {text}\n",
        "    sentiment:\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = smart_llm_invoke(prompt)\n",
        "        sentiment_score = float(response.strip())\n",
        "        return max(-1, min(1, sentiment_score))\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # Fallback to keyword-based analysis\n",
        "    positive_words = [\n",
        "        'gain', 'gains', 'up', 'rise', 'surge', 'rally', 'jump', 'soar',\n",
        "        'climb', 'boost', 'profit', 'growth', 'outperform', 'beat', 'strong',\n",
        "        'bullish', 'optimistic', 'confidence', 'upgrade', 'buy', 'positive'\n",
        "    ]\n",
        "\n",
        "    negative_words = [\n",
        "        'loss', 'down', 'drop', 'fall', 'decline', 'plunge', 'crash',\n",
        "        'tumble', 'slump', 'miss', 'disappoint', 'weak', 'bearish',\n",
        "        'pessimistic', 'concern', 'worry', 'fear', 'downgrade', 'sell'\n",
        "    ]\n",
        "\n",
        "    intensifiers = ['very', 'extremely', 'highly', 'significantly']\n",
        "    negations = ['not', 'no', 'never', \"don't\", \"doesn't\", \"won't\"]\n",
        "\n",
        "    words = text.lower().split()\n",
        "    positive_count = 0\n",
        "    negative_count = 0\n",
        "\n",
        "    for i, word in enumerate(words):\n",
        "        # Check for intensifiers\n",
        "        multiplier = 1.5 if i > 0 and words[i-1] in intensifiers else 1.0\n",
        "\n",
        "        # Check for negations (flip sentiment)\n",
        "        is_negated = i > 0 and words[i-1] in negations\n",
        "\n",
        "        if word in positive_words:\n",
        "            if is_negated:\n",
        "                negative_count += multiplier\n",
        "            else:\n",
        "                positive_count += multiplier\n",
        "        elif word in negative_words:\n",
        "            if is_negated:\n",
        "                positive_count += multiplier\n",
        "            else:\n",
        "                negative_count += multiplier\n",
        "\n",
        "    if positive_count + negative_count == 0:\n",
        "        return 0.0\n",
        "\n",
        "    return (positive_count - negative_count) / (positive_count + negative_count)"
      ],
      "metadata": {
        "id": "IYpfw7IE6DpO"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the heart of the model that connects the model through a RAG pipeline\n",
        "class NewsRAG:\n",
        "  def __init__(self, embedding_model=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
        "    self.embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=embedding_model\n",
        "    )\n",
        "    self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=500,\n",
        "        chunk_overlap=50\n",
        "    )\n",
        "    self.vectorstore = None\n",
        "  def index_news(self, news_articles: List[Dict]):\n",
        "    \"\"\"\n",
        "    news_articles example:\n",
        "    {\n",
        "        \"title\": \"...\",\n",
        "        \"content\": \"...\",\n",
        "        \"link\": \"...\",\n",
        "        \"date\": \"...\",\n",
        "        \"source\": \"...\"\n",
        "    }\n",
        "    \"\"\"\n",
        "    documents = []\n",
        "    for article in news_articles:\n",
        "        content = article.get(\"content\", \"\") or article.get(\"title\", \"\")\n",
        "        header=f\"Source: {article.get('source')}| Date: {article.get('date')}\"\n",
        "        metadata = {\n",
        "            \"title\": article.get(\"title\", \"\"),\n",
        "            \"link\": article.get(\"link\", \"\"),\n",
        "            \"date\": article.get(\"date\", \"\"),\n",
        "            \"source\": article.get(\"source\", \"\")\n",
        "        }\n",
        "\n",
        "        documents.append(\n",
        "            Document(\n",
        "                page_content=content,\n",
        "                metadata=metadata\n",
        "            )\n",
        "        )\n",
        "    if documents:\n",
        "      splits = self.text_splitter.split_documents(documents)\n",
        "      self.vectorstore = Chroma.from_documents(\n",
        "          documents=splits,\n",
        "          embedding=self.embeddings\n",
        "      )\n",
        "\n",
        "  def retrieve_context(self, query: str, k: int = 5) -> List[Dict]:\n",
        "    if self.vectorstore is None:\n",
        "      return []\n",
        "    docs = self.vectorstore.similarity_search(query, k=k)\n",
        "    return self.__distill_context(query, docs)\n",
        "\n",
        "  def __distill_context(self, query: str, docs: List[Document]) -> List[Dict]:\n",
        "    raw_text=\"\\n--\\n\".join([d.page_content for d in docs])\n",
        "    distil_prompts=f\"\"\"\n",
        "        Extract ONLY the facts from the news snippets below that directly answer the query: \"{query}\"\n",
        "        If the snippets are irrelevant, return \"No relevant news found.\"\n",
        "\n",
        "        Snippets:\n",
        "        {raw_text}\n",
        "\n",
        "        Key Facts:\n",
        "        \"\"\"\n",
        "    response = smart_llm_invoke(distil_prompts)\n",
        "    return response.strip().split(\"\\n--\\n\")"
      ],
      "metadata": {
        "id": "TzDfoyru7TAy"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    query: str\n",
        "    ticker: str\n",
        "    intent: str\n",
        "    price_data: dict\n",
        "    financial_data: dict\n",
        "    news_articles: Annotated[list, operator.add]\n",
        "    news_context: Annotated[list, operator.add]\n",
        "    sentiment_score: float\n",
        "    analysis: str\n",
        "    recommendation: str\n",
        "    messages: list       # Remove Annotated"
      ],
      "metadata": {
        "id": "03-EXbKtcsyN"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def intent_classifier(state: AgentState):\n",
        "    query = state['query']\n",
        "    query_lower = query.lower()\n",
        "\n",
        "    # Check for specific milestone questions (like \"when did X hit Y\")\n",
        "    if any(word in query_lower for word in ['when did', 'when was']) and any(word in query_lower for word in ['hit', 'reach', 'achieve', 'cross']):\n",
        "        intent = 'milestone_query'\n",
        "    elif any(word in query_lower for word in ['why', 'reason', 'cause']):\n",
        "        intent = 'reason_query'\n",
        "    elif any(word in query_lower for word in ['when', 'trend', 'history']):\n",
        "        intent = 'trend_analysis'\n",
        "    elif any(word in query_lower for word in ['compare', 'vs', 'versus']):\n",
        "        intent = 'comparison'\n",
        "    elif any(word in query_lower for word in ['price', 'cost', 'trading at']):\n",
        "        intent = 'price_query'\n",
        "    else:\n",
        "        intent = 'general'\n",
        "\n",
        "    state['intent'] = intent\n",
        "    state['messages'].append(f\"[Intent Classifier] Intent: {intent}\")\n",
        "    return state"
      ],
      "metadata": {
        "id": "-2CCz_-_gIgc"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ticker_extractor(state):\n",
        "    query = state[\"query\"].strip()\n",
        "    q_upper = query.upper()\n",
        "\n",
        "    # 1ï¸âƒ£ Explicit ticker check\n",
        "    explicit_ticker_pattern = r'\\b[A-Z&]{2,10}\\.[A-Z]{1,4}\\b|\\$[A-Z]{2,5}\\b'\n",
        "    explicit_matches = re.findall(explicit_ticker_pattern, q_upper)\n",
        "\n",
        "    for raw in explicit_matches:\n",
        "        ticker = raw.replace(\"$\", \"\").strip()\n",
        "        if validate_ticker(ticker):\n",
        "            state[\"ticker\"] = ticker\n",
        "            state[\"messages\"].append(f\"[Ticker Extractor] Explicit ticker: {ticker}\")\n",
        "            return state\n",
        "\n",
        "    # 2ï¸âƒ£ Extract company name\n",
        "    extract_prompt = f\"\"\"Extract ONLY the company name from this query. Return just the company name, nothing else.\n",
        "\n",
        "Query: {query}\n",
        "\n",
        "Company name:\"\"\"\n",
        "\n",
        "    company_name = smart_llm_invoke(extract_prompt).strip()\n",
        "\n",
        "    # 3ï¸âƒ£ Yahoo Finance Lookup with ranking\n",
        "    def yahoo_lookup_best_match(search_term):\n",
        "        \"\"\"Use Yahoo Finance search and return the most relevant result\"\"\"\n",
        "        try:\n",
        "            url = \"https://query2.finance.yahoo.com/v1/finance/search\"\n",
        "            params = {\n",
        "                'q': search_term,\n",
        "                'quotesCount': 10,  # Get more results\n",
        "                'newsCount': 0,\n",
        "                'enableFuzzyQuery': False,\n",
        "                'quotesQueryId': 'tss_match_phrase_query'\n",
        "            }\n",
        "            headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "            response = requests.get(url, params=params, headers=headers, timeout=5)\n",
        "            data = response.json()\n",
        "\n",
        "            quotes = data.get('quotes', [])\n",
        "            if not quotes:\n",
        "                return None\n",
        "\n",
        "            # Score each result for relevance\n",
        "            def score_result(quote):\n",
        "                score = 0\n",
        "                symbol = quote.get('symbol', '')\n",
        "                name = quote.get('longname', '') or quote.get('shortname', '')\n",
        "                exchange = quote.get('exchange', '')\n",
        "                quote_type = quote.get('quoteType', '')\n",
        "\n",
        "                # Prefer exact company name matches\n",
        "                if search_term.lower() in name.lower():\n",
        "                    score += 100\n",
        "\n",
        "                # Prefer EQUITY over other types\n",
        "                if quote_type == 'EQUITY':\n",
        "                    score += 50\n",
        "\n",
        "                # Prefer major exchanges\n",
        "                if exchange in ['NSI', 'BSE', 'NMS', 'NYQ']:\n",
        "                    score += 30\n",
        "\n",
        "                # Penalize subsidiaries/specific divisions (usually longer names)\n",
        "                if len(name) > len(search_term) + 20:\n",
        "                    score -= 20\n",
        "\n",
        "                # Prefer shorter, cleaner ticker symbols\n",
        "                if len(symbol) <= 10:\n",
        "                    score += 10\n",
        "\n",
        "                # Prefer symbols without special chars (except .NS, .BO)\n",
        "                base_symbol = symbol.split('.')[0]\n",
        "                if base_symbol.isalpha():\n",
        "                    score += 10\n",
        "\n",
        "                return score\n",
        "\n",
        "            # Rank results\n",
        "            ranked = sorted(quotes, key=score_result, reverse=True)\n",
        "\n",
        "            # Return top match\n",
        "            return ranked[0].get('symbol')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Yahoo lookup failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    # Try Yahoo lookup\n",
        "    ticker = yahoo_lookup_best_match(company_name)\n",
        "\n",
        "    if ticker and validate_ticker(ticker):\n",
        "        state[\"ticker\"] = ticker\n",
        "        state[\"messages\"].append(f\"[Ticker Extractor] Found via Yahoo: {ticker}\")\n",
        "        return state\n",
        "\n",
        "    # 4ï¸âƒ£ LLM fallback with disambiguation\n",
        "    llm_prompt = f\"\"\"What is the PRIMARY/MAIN stock ticker symbol for \"{company_name}\"?\n",
        "\n",
        "IMPORTANT: If there are multiple companies with similar names, return the LARGEST/MOST WELL-KNOWN one.\n",
        "\n",
        "Examples:\n",
        "- \"Mahindra\" â†’ M&M.NS (Mahindra & Mahindra, the main automobile company, NOT subsidiaries)\n",
        "- \"Tata\" â†’ TATAMOTORS.NS (the main auto company)\n",
        "- \"Adani\" â†’ ADANI.NS (Adani Enterprises, the flagship)\n",
        "- \"Apple\" â†’ AAPL (the main company)\n",
        "\n",
        "For Indian companies: use .NS suffix\n",
        "For US companies: no suffix\n",
        "\n",
        "Company: {company_name}\n",
        "\n",
        "Main ticker symbol:\"\"\"\n",
        "\n",
        "    ticker_response = smart_llm_invoke(llm_prompt).strip().upper()\n",
        "\n",
        "    # Extract ticker\n",
        "    match = re.search(r'\\b[A-Z&]{1,15}\\.(?:NS|BO)\\b|\\b[A-Z]{1,5}\\b', ticker_response)\n",
        "    ticker = match.group(0) if match else ticker_response\n",
        "\n",
        "    # Validate\n",
        "    if ticker and validate_ticker(ticker):\n",
        "        state[\"ticker\"] = ticker\n",
        "        state[\"messages\"].append(f\"[Ticker Extractor] LLM resolved: {ticker}\")\n",
        "        return state\n",
        "\n",
        "    # Failed\n",
        "    state[\"ticker\"] = \"\"\n",
        "    state[\"messages\"].append(f\"[Ticker Extractor] Could not find ticker for {company_name}\")\n",
        "\n",
        "    return state"
      ],
      "metadata": {
        "id": "_23gH8FVAPfg"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def price_fetcher(state: AgentState):\n",
        "  ticker=state['ticker']\n",
        "  if ticker:\n",
        "    price_data=get_stock_price(ticker)\n",
        "    state['price_data']=price_data\n",
        "    state['messages'].append(f\"[Price Fetcher] Price Data: {price_data}\")\n",
        "  else:\n",
        "    state['price_data']={}\n",
        "    state['messages'].append(f\"[Price Fetcher] No price data found\")\n",
        "  return state"
      ],
      "metadata": {
        "id": "cfX7ygAEcyub"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def financial_fetcher(state: AgentState):\n",
        "  ticker=state['ticker']\n",
        "  intent=state['intent']\n",
        "  if intent in ['general', 'comparison'] and ticker:\n",
        "    financial_data=fetch_financial_statements(ticker, 'annual')\n",
        "    state['financial_data']=financial_data\n",
        "    state['messages'].append(f\"[Financial Fetcher] Financial Data: {financial_data}\")\n",
        "  else:\n",
        "    state['financial_data']={}\n",
        "    state['messages'].append(f\"[Financial Fetcher] No financial data found\")\n",
        "  return state"
      ],
      "metadata": {
        "id": "A6JAhSvddVNI"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def news_fetcher(state: AgentState):\n",
        "    \"\"\"Fetches news articles using NewsAPI\"\"\"\n",
        "    ticker = state.get('ticker')\n",
        "\n",
        "    if not ticker:\n",
        "        state['news_articles'] = []\n",
        "        state.setdefault('messages', []).append(\"[News Fetcher] No ticker provided\")\n",
        "        return state\n",
        "\n",
        "    import traceback\n",
        "    from datetime import datetime, timedelta\n",
        "\n",
        "    try:\n",
        "        # Initialize NewsAPI\n",
        "        try:\n",
        "            api_key = userdata.get('NEWSAPI_KEY')\n",
        "            newsapi = NewsApiClient(api_key=api_key)\n",
        "        except Exception as e:\n",
        "            state['news_articles'] = []\n",
        "            state.setdefault('messages', []).append(f\"[News Fetcher] API initialization failed: {e}\")\n",
        "            return state\n",
        "\n",
        "        # Get company info\n",
        "        clean_ticker = ticker.split('.')[0]\n",
        "        price_data = state.get('price_data', {})\n",
        "        company_name = price_data.get('company_name', clean_ticker)\n",
        "\n",
        "        # Calculate date range\n",
        "        intent = state.get('intent', '')\n",
        "        from_date = (datetime.now() - timedelta(days=30)).strftime('%Y-%m-%d')\n",
        "\n",
        "        articles = []\n",
        "        seen_urls = set()\n",
        "\n",
        "        # Try multiple query strategies\n",
        "        queries = [\n",
        "            company_name,\n",
        "            f\"{clean_ticker}\",\n",
        "            f\"{company_name} stock\",\n",
        "            f\"{company_name} India\",\n",
        "        ]\n",
        "\n",
        "        for query in queries:\n",
        "            try:\n",
        "                # Make API call\n",
        "                response = newsapi.get_everything(\n",
        "                    q=query,\n",
        "                    from_param=from_date,\n",
        "                    language='en',\n",
        "                    sort_by='publishedAt',\n",
        "                    page_size=20\n",
        "                )\n",
        "\n",
        "                status = response.get('status')\n",
        "                news_items = response.get('articles', [])\n",
        "\n",
        "                if status != 'ok':\n",
        "                    continue\n",
        "\n",
        "                # Process articles\n",
        "                for item in news_items:\n",
        "                    url = item.get('url', '')\n",
        "\n",
        "                    if not url or url in seen_urls:\n",
        "                        continue\n",
        "                    seen_urls.add(url)\n",
        "\n",
        "                    # Extract source\n",
        "                    source_obj = item.get('source', {})\n",
        "                    source_name = source_obj.get('name', '') if isinstance(source_obj, dict) else str(source_obj)\n",
        "\n",
        "                    # Content\n",
        "                    content = item.get('description') or item.get('content') or item.get('title', '')\n",
        "\n",
        "                    # Date\n",
        "                    published_date = item.get('publishedAt', '')\n",
        "                    try:\n",
        "                        date_obj = datetime.fromisoformat(published_date.replace('Z', '+00:00'))\n",
        "                        formatted_date = date_obj.strftime('%Y-%m-%d')\n",
        "                    except:\n",
        "                        formatted_date = published_date\n",
        "\n",
        "                    articles.append({\n",
        "                        'title': item.get('title', ''),\n",
        "                        'content': content,\n",
        "                        'link': url,\n",
        "                        'date': formatted_date,\n",
        "                        'source': source_name\n",
        "                    })\n",
        "\n",
        "                # Stop if we have enough\n",
        "                if len(articles) >= 20:\n",
        "                    break\n",
        "\n",
        "            except Exception as e:\n",
        "                continue\n",
        "\n",
        "        # Update state\n",
        "        state['news_articles'] = articles\n",
        "        state.setdefault('messages', [])\n",
        "        state['messages'].append(f\"[News Fetcher] Found {len(articles)} articles for {ticker}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        state['news_articles'] = []\n",
        "        state.setdefault('messages', []).append(f\"[News Fetcher] Error: {str(e)}\")\n",
        "\n",
        "    return state"
      ],
      "metadata": {
        "id": "umQuooOqd3ix"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def news_analyzer(state: AgentState):\n",
        "  print(f\"[NEWS ANALYZER DEBUG] Received {len(state.get('news_articles', []))} articles\")\n",
        "  news_articles = state['news_articles']\n",
        "  if not news_articles:\n",
        "    state['news_context']=[]\n",
        "    state['messages'].append(f\"[News Analyzer] No news articles to analyze\")\n",
        "    return state\n",
        "  rag=NewsRAG()\n",
        "  rag.index_news(news_articles)\n",
        "\n",
        "  context=state['news_context']\n",
        "  if not context:\n",
        "    context=rag.retrieve_context(state['query'])\n",
        "  state['news_context']=context\n",
        "\n",
        "  sentiment=analyze_sentiment(\"\\n--\\n\".join(context))\n",
        "  state['sentiment_score']=sentiment\n",
        "\n",
        "  state['messages'].append(f\"[News Analyzer] Sentiment Score: {sentiment}\")\n",
        "  return state"
      ],
      "metadata": {
        "id": "LE8QITsWfGss"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response_generator(state: AgentState):\n",
        "    \"\"\"Generate final response based on all gathered data\"\"\"\n",
        "    query = state['query']\n",
        "    ticker = state['ticker']\n",
        "    intent = state['intent']\n",
        "    price_data = state['price_data']\n",
        "    news_context = state['news_context']\n",
        "    news_articles = state.get('news_articles', [])\n",
        "    sentiment = state['sentiment_score']\n",
        "    symbol = fetch_currency(ticker)[0]\n",
        "\n",
        "    # Build context for LLM\n",
        "    context_parts = []\n",
        "\n",
        "    if price_data and 'error' not in price_data:\n",
        "        context_parts.append(f\"\"\"\n",
        "ðŸ“ˆ Stock Data for {ticker}\n",
        "\n",
        "ðŸ’° Price & Trading\n",
        "- Current Price: {symbol}{price_data.get('current_price', 0):.2f}\n",
        "- Previous Close: {symbol}{price_data.get('previous_close', 0):.2f}\n",
        "- Open: {symbol}{price_data.get('open', 0):.2f}\n",
        "- Day High / Low: {symbol}{price_data.get('day_high', 0):.2f} / ${price_data.get('day_low', 0):.2f}\n",
        "- 52-Week High / Low: {symbol}{price_data.get('52_week_high', 0):.2f} / ${price_data.get('52_week_low', 0):.2f}\n",
        "- Volume: {price_data.get('volume', 0):,}\n",
        "- Avg Volume (3M): {price_data.get('avg_volume', 0):,}\n",
        "\n",
        "ðŸ“Š Averages & Momentum\n",
        "- 50-Day Avg: {symbol}{price_data.get('50_day_average', 0):.2f}\n",
        "- 200-Day Avg: {symbol}{price_data.get('200_day_average', 0):.2f}\n",
        "- Beta (Volatility): {price_data.get('beta', 'N/A')}\n",
        "\n",
        "ðŸ¦ Valuation\n",
        "- Market Cap: {symbol}{price_data.get('market_cap', 0):,.0f}\n",
        "- Enterprise Value: {symbol}{price_data.get('enterprise_value', 0):,.0f}\n",
        "- P/E Ratio (TTM): {price_data.get('pe_ratio', 'N/A')}\n",
        "- Forward P/E: {price_data.get('forward_pe', 'N/A')}\n",
        "- PEG Ratio: {price_data.get('peg_ratio', 'N/A')}\n",
        "- Price to Book: {price_data.get('price_to_book', 'N/A')}\n",
        "\n",
        "ðŸ“‰ Financial Health\n",
        "- Revenue (TTM): {symbol}{price_data.get('revenue', 0):,.0f}\n",
        "- Revenue Growth (YoY): {price_data.get('revenue_growth', 'N/A')}\n",
        "- Gross Margin: {price_data.get('gross_margin', 'N/A')}\n",
        "- Operating Margin: {price_data.get('operating_margin', 'N/A')}\n",
        "- Net Margin: {price_data.get('profit_margin', 'N/A')}\n",
        "- Free Cash Flow: {symbol}{price_data.get('free_cashflow', 0):,.0f}\n",
        "- Debt to Equity: {price_data.get('debt_to_equity', 'N/A')}\n",
        "- Return on Equity (ROE): {price_data.get('roe', 'N/A')}\n",
        "\n",
        "ðŸ’¸ Dividends\n",
        "- Dividend Rate: {symbol}{price_data.get('dividend_rate', 0):.2f}\n",
        "- Dividend Yield: {price_data.get('dividend_yield', 'N/A')}\n",
        "- Payout Ratio: {price_data.get('payout_ratio', 'N/A')}\n",
        "\n",
        "ðŸ§  Analyst View\n",
        "- Recommendation: {price_data.get('recommendation_key', 'N/A')}\n",
        "- Target Mean Price: {symbol}{price_data.get('target_mean_price', 0):.2f}\n",
        "- Target High / Low: {symbol}{price_data.get('target_high_price', 0):.2f} / ${price_data.get('target_low_price', 0):.2f}\n",
        "- Number of Analysts: {price_data.get('number_of_analyst_opinions', 'N/A')}\n",
        "\n",
        "ðŸ•’ Trading Info\n",
        "- Currency: {price_data.get('currency', 'USD')}\n",
        "- Exchange: {price_data.get('exchange', 'N/A')}\n",
        "- Market State: {price_data.get('market_state', 'N/A')}\n",
        "\"\"\")\n",
        "\n",
        "    if news_context:\n",
        "        context_parts.append(f\"Recent News Context:\\n\" + \"\\n\".join(news_context))\n",
        "\n",
        "    context_parts.append(f\"Overall Sentiment Score: {sentiment:.2f} (-1 = very negative, 1 = very positive)\")\n",
        "\n",
        "    full_context = \"\\n\\n\".join(context_parts)\n",
        "\n",
        "    # Create prompt based on intent\n",
        "    if intent == 'reason_query':\n",
        "        prompt = f\"\"\"You are a financial analyst. Based on the data below, explain WHY {ticker} stock moved recently.\n",
        "\n",
        "{full_context}\n",
        "\n",
        "User Question: {query}\n",
        "\n",
        "Instructions:\n",
        "- Write in clear, professional prose (not bullet points)\n",
        "- Cite specific events or news\n",
        "- Be concise (2-3 sentences max)\n",
        "- Do NOT copy/paste news headlines\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "    elif intent == 'trend_analysis':\n",
        "        prompt = f\"\"\"You are a financial analyst. Based on the data below, analyze WHEN and HOW {ticker} has been trending.\n",
        "\n",
        "{full_context}\n",
        "\n",
        "User Question: {query}\n",
        "\n",
        "Instructions:\n",
        "- Answer the specific timing question asked\n",
        "- Reference price movements and dates if available\n",
        "- Be concise (2-3 sentences max)\n",
        "- Write in clear prose, not headlines\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "    elif intent == 'price_query':\n",
        "        prompt = f\"\"\"Based on the stock data below, answer this price question about {ticker}.\n",
        "\n",
        "{full_context}\n",
        "\n",
        "User Question: {query}\n",
        "\n",
        "Instructions:\n",
        "- Give the specific price information requested\n",
        "- Be direct and accurate\n",
        "- Keep it brief (1-2 sentences)\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "    elif intent == 'milestone_query':\n",
        "        prompt = f\"\"\"Answer this question about {ticker} stock using the data below.\n",
        "\n",
        "Current market cap: ${price_data.get('market_cap', 0):,.0f}\n",
        "\n",
        "Question: {query}\n",
        "\n",
        "News headlines:\n",
        "{chr(10).join([f\"- {a.get('title', '')}\" for a in news_articles[:5]])}\n",
        "\n",
        "Answer the question directly. If the milestone isn't mentioned in the news, say \"No recent news about this milestone.\"\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "    else:\n",
        "        prompt = f\"\"\"Based on the stock data and news below, answer this question about {ticker}.\n",
        "\n",
        "{full_context}\n",
        "\n",
        "User Question: {query}\n",
        "\n",
        "Instructions:\n",
        "- Provide a helpful, accurate response\n",
        "- Write in clear prose\n",
        "- Be concise\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "    # Get response from LLM\n",
        "    response_text = smart_llm_invoke(prompt)\n",
        "\n",
        "    # Add sources if news articles exist\n",
        "    if news_articles and len(news_articles) > 0:\n",
        "        response_text += \"\\n\\n**Sources:**\"\n",
        "        for i, article in enumerate(news_articles[:5], 1):\n",
        "            response_text += f\"\\n{i}. [{article.get('title', 'No title')}]({article.get('link', '#')}) - {article.get('source', 'Unknown')} ({article.get('date', 'No date')})\"\n",
        "\n",
        "    state['analysis'] = response_text\n",
        "\n",
        "    return state"
      ],
      "metadata": {
        "id": "BeNaONHsfoDE"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_workflow():\n",
        "    workflow = StateGraph(AgentState)\n",
        "\n",
        "\n",
        "    workflow.add_node(\"intent_classifier\", intent_classifier)\n",
        "    workflow.add_node(\"ticker_extractor\", ticker_extractor)\n",
        "    workflow.add_node(\"price_fetcher\", price_fetcher)\n",
        "    workflow.add_node(\"financial_fetcher\", financial_fetcher)\n",
        "    workflow.add_node(\"news_fetcher\", news_fetcher)\n",
        "    workflow.add_node(\"news_analyzer\", news_analyzer)\n",
        "    workflow.add_node(\"response_generator\", response_generator)\n",
        "\n",
        "    workflow.add_edge(START, \"intent_classifier\")\n",
        "    workflow.add_edge(\"intent_classifier\", \"ticker_extractor\")\n",
        "    workflow.add_edge(\"ticker_extractor\", \"price_fetcher\")\n",
        "    workflow.add_edge(\"price_fetcher\", \"financial_fetcher\")\n",
        "    workflow.add_edge(\"financial_fetcher\", \"news_fetcher\")\n",
        "    workflow.add_edge(\"news_fetcher\", \"news_analyzer\")\n",
        "    workflow.add_edge(\"news_analyzer\", \"response_generator\")\n",
        "    workflow.add_edge(\"response_generator\", END)\n",
        "\n",
        "    return workflow.compile()\n",
        "agent = build_workflow()"
      ],
      "metadata": {
        "id": "Yx1lErg_gZS8"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_currency(ticker: str):\n",
        "    \"\"\"\n",
        "    Returns (currency_symbol, currency_code)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        info = yf.Ticker(ticker).info\n",
        "        currency_code = info.get(\"currency\", \"USD\")\n",
        "    except Exception:\n",
        "        currency_code = \"USD\"\n",
        "\n",
        "    SYMBOL_MAP = {\n",
        "        \"USD\": \"$\", \"INR\": \"â‚¹\", \"EUR\": \"â‚¬\", \"GBP\": \"Â£\",\n",
        "        \"JPY\": \"Â¥\", \"CNY\": \"Â¥\", \"HKD\": \"HK$\",\n",
        "        \"AUD\": \"A$\", \"CAD\": \"C$\", \"CHF\": \"CHF\",\n",
        "        \"KRW\": \"â‚©\", \"BRL\": \"R$\", \"ZAR\": \"R\"\n",
        "    }\n",
        "\n",
        "    symbol = SYMBOL_MAP.get(currency_code, currency_code + \" \")\n",
        "    return symbol, currency_code\n"
      ],
      "metadata": {
        "id": "vXPMC0JIYm0-"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_stocks(user_query: str):\n",
        "    initial_state = {\n",
        "        'query': user_query,\n",
        "        'ticker': '',\n",
        "        'intent': '',\n",
        "        'price_data': {},\n",
        "        'financial_data': {},\n",
        "        'news_articles': [],  # Start empty\n",
        "        'news_context': [],\n",
        "        'sentiment_score': 0.0,\n",
        "        'analysis': '',\n",
        "        'recommendation': '',\n",
        "        'messages': []\n",
        "    }\n",
        "\n",
        "    result = agent.invoke(initial_state)\n",
        "\n",
        "    return {\n",
        "        'answer': result['analysis'],\n",
        "        'ticker': result['ticker'],\n",
        "        'sentiment': result['sentiment_score'],\n",
        "        'debug_messages': result['messages']\n",
        "    }"
      ],
      "metadata": {
        "id": "97yTJnkShTzb"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result1 = query_stocks(\"Is the stock price of BMW rising?\" )\n",
        "print(f\"Query:Is the stock price of BMW rising?\")\n",
        "print(f\"Answer: {result1['answer']}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4PLQwmohePK",
        "outputId": "93881b25-855c-4b1b-dc0b-295d53b58bfa"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NEWS ANALYZER DEBUG] Received 34 articles\n",
            "Query:Is the stock price of BMW rising?\n",
            "Answer: Yes, the stock price of BMW.BO is rising. The current price is â‚¹37.76, up from the previous close of â‚¹37.73.\n",
            "\n",
            "**Sources:**\n",
            "1. [Recycled Carbon Fiber Industry Outlook Report 2026: A $263.87 Million Market by 2033 | Astute Analytica](https://www.globenewswire.com/news-release/2026/01/22/3224202/0/en/Recycled-Carbon-Fiber-Industry-Outlook-Report-2026-A-263-87-Million-Market-by-2033-Astute-Analytica.html) - GlobeNewswire (2026-01-22)\n",
            "2. [Indonesia Used Car Market Report 2026-2031: Odometer Fraud Persists, Highlighting Need for AI Inspections in Indonesia's Used Car Sector](https://www.globenewswire.com/news-release/2026/01/22/3223661/28124/en/Indonesia-Used-Car-Market-Report-2026-2031-Odometer-Fraud-Persists-Highlighting-Need-for-AI-Inspections-in-Indonesia-s-Used-Car-Sector.html) - GlobeNewswire (2026-01-22)\n",
            "3. [Bulletproof Armored Vehicle Research Report 2026: $21.83 Bn Market Opportunities, Trends, Competitive Landscape, Strategies, and Forecasts, 2020-2025, 2025-2030F, 2035F](https://www.globenewswire.com/news-release/2026/01/21/3222537/28124/en/Bulletproof-Armored-Vehicle-Research-Report-2026-21-83-Bn-Market-Opportunities-Trends-Competitive-Landscape-Strategies-and-Forecasts-2020-2025-2025-2030F-2035F.html) - GlobeNewswire (2026-01-21)\n",
            "4. [Autonomous Vehicle Market Surges with 34.84% CAGR as MaaS, ADAS, and AI Adoption Accelerate](https://www.globenewswire.com/news-release/2026/01/19/3221004/0/en/Autonomous-Vehicle-Market-Surges-with-34-84-CAGR-as-MaaS-ADAS-and-AI-Adoption-Accelerate.html) - GlobeNewswire (2026-01-19)\n",
            "5. [Lithium Metal Battery Materials Market Volume Worth 1,549,218.4 tons by 2035](https://www.globenewswire.com/news-release/2026/01/19/3220891/0/en/Lithium-Metal-Battery-Materials-Market-Volume-Worth-1-549-218-4-tons-by-2035.html) - GlobeNewswire (2026-01-19)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}