{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPj5dRgft0wAJtoSHrqScQF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PranavSuresh525/AI-ML-Projects/blob/main/AI_Integration_in_Finance/Finance_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aBQwkq0Bf86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e302acc1-f7a4-456d-d80b-7c7f57ad6e89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m157.4/157.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.1/127.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m719.4/719.4 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m234.9/234.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# All the imports necessary\n",
        "!pip install -q -U --no-warn-conflicts \\\n",
        "    langchain-huggingface \\\n",
        "    langchain-google-genai \\\n",
        "    langgraph \\\n",
        "    yfinance \\\n",
        "    gnews \\\n",
        "    transformers \\\n",
        "    accelerate \\\n",
        "    duckduckgo-search \\\n",
        "    langchain-text-splitters \\\n",
        "    langchain-chroma\n",
        "\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import operator\n",
        "from datetime import datetime, timedelta\n",
        "from typing import TypedDict, List, Annotated, Dict, Any, Optional\n",
        "import yfinance as yf\n",
        "from gnews import GNews\n",
        "from transformers import pipeline\n",
        "from langchain_huggingface import HuggingFacePipeline, HuggingFaceEmbeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_community.tools import DuckDuckGoSearchRun\n",
        "from langchain_core.messages import HumanMessage, BaseMessage\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.documents import Document\n",
        "from langgraph.graph import StateGraph, END, START\n",
        "from IPython.display import HTML"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## the local llm whixh avoids unecessary calls from gemini as there is a API limit\n",
        "local_pipe = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\", max_new_tokens=256, device_map=\"auto\")\n",
        "local_llm = HuggingFacePipeline(pipeline=local_pipe)\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBwd900WvchgpYVF0nivT5TO0uE9kdSyTk\"\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-exp\",\n",
        "    temperature=0.2,\n",
        "    google_api_key=os.environ[\"GOOGLE_API_KEY\"]\n",
        ")\n",
        "# WEB SEARCH: Used by the local node to find tickers\n",
        "search_tool = DuckDuckGoSearchRun()\n",
        "_ticker_cache={}"
      ],
      "metadata": {
        "id": "sByPkSlVF_nX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a basic function to get all the info related to a stock\n",
        "def get_stock_price(ticker: str):\n",
        "  try:\n",
        "    stock = yf.Ticker(ticker)\n",
        "    info = stock.info\n",
        "    history = stock.history(period='1y')\n",
        "\n",
        "    if not info or not info.get('symbol') or history.empty:\n",
        "      return {\"error\": f\"No data found or invalid ticker for {ticker}\"}\n",
        "\n",
        "    return{\n",
        "            'ticker': ticker,\n",
        "            'current_price': info.get('currentPrice', 0),\n",
        "            'previous_close': info.get('previousClose', 0),\n",
        "            'day_high': info.get('dayHigh', 0),\n",
        "            'day_low': info.get('dayLow', 0),\n",
        "            'volume': info.get('volume', 0),\n",
        "            'market_cap': info.get('marketCap', 0),\n",
        "            'company_name': info.get('longName', ticker),\n",
        "            'pe_ratio': info.get('trailingPE', 0),\n",
        "            'dividend_yield': info.get('dividendYield', 0),\n",
        "            'target_mean_price': info.get('targetMeanPrice', 0),\n",
        "            'recommendation_key': info.get('recommendationKey', 'N/A'),\n",
        "            '50_day_average': history['Close'].rolling(window=50).mean().iloc[-1] if len(history) >= 50 else 0,\n",
        "            '200_day_average': history['Close'].rolling(window=200).mean().iloc[-1] if len(history) >= 200 else 0,\n",
        "            'price_history': history['Close'].tail(30).to_list()\n",
        "        }\n",
        "  except Exception as e:\n",
        "        return {\"error\": f\"Failed to fetch data for {ticker}: {str(e)}\"}"
      ],
      "metadata": {
        "id": "V19ta-92QLfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a function which accesses a pandas data frame and gets the latest stock price of the company-'item' here\n",
        "def get_recent_data(df, items):\n",
        "  if df.empty:\n",
        "    return {}\n",
        "  recent_data={}\n",
        "  for item in items:\n",
        "    try:\n",
        "      if item in df.index:\n",
        "          value = df.loc[item].iloc[0]\n",
        "          recent_data[item] = float(value) if value is not None else 0\n",
        "      else:\n",
        "          recent_data[item] = 0\n",
        "    except:\n",
        "      recent_data[item] = 0\n"
      ],
      "metadata": {
        "id": "Q6rMmwMGSldA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a function which basically gets the latest info (listed below) from yahoo finance, uses the period here to know how long to look for\n",
        "def fetch_financial_statements(ticker: str, period: str)->dict:\n",
        "  try:\n",
        "    stock=yf.Ticker(ticker)\n",
        "    if not stock.info or not stock.info.get('symbol'):\n",
        "      return {'error': f'Invalid or no data for ticker {ticker}'}\n",
        "\n",
        "    if period=='quaterly':\n",
        "      balance_sheet=stock.quarterly_balance_sheet\n",
        "      income_statement=stock.quarterly_income_stmt\n",
        "      cash_flow=stock.quarterly_cashflow\n",
        "    else:\n",
        "      balance_sheet=stock.balance_sheet\n",
        "      income_statement=stock.income_stmt\n",
        "      cash_flow=stock.cashflow\n",
        "    return{\n",
        "        'balance_sheet': get_recent_data(balance_sheet, ['Total Cash', 'Total Debt']),\n",
        "        'income_statement': get_recent_data(income_statement, ['Total Revenue', 'Gross Profit']),\n",
        "        'cash_flow': get_recent_data(cash_flow, ['Net Cash Flow']),\n",
        "        'period': period\n",
        "    }\n",
        "  except Exception as e:\n",
        "    return {\"error\": f\"Failed to fetch data for {ticker}: {str(e)}\"}"
      ],
      "metadata": {
        "id": "v8_nylfNUsdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a simple validate function that cross checks with yf to see of the ticker exist\n",
        "def validate_ticker(potential_ticker: str):\n",
        "  try:\n",
        "    stock = yf.Ticker(potential_ticker)\n",
        "    info = stock.info\n",
        "    if info and 'symbol' in info and info.get('symbol'):\n",
        "      return info['symbol']\n",
        "    return None\n",
        "  except Exception as e:\n",
        "    return None"
      ],
      "metadata": {
        "id": "yEt8fO7LXq2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a complex function to analyse sentiments, uses the local llm's response to gauge the market trends, it does this by looking\n",
        "# for the list of positive words,negetive words,intensifiers and negations then proceeds to assign a valure of 1/-1 to these\n",
        "# words then returns (positive-ngetive)/(positive+ negetive)\n",
        "def analyze_sentiment(text: str):\n",
        "  if not text:\n",
        "        return 0.0\n",
        "  prompt = f\"\"\"Analyze the sentiment of this financial news text.\n",
        "  Return ONLY a number between -1 (very negative) and 1 (very positive).\n",
        "\n",
        "  Text: {text}\n",
        "  sentiment:\"\"\"\n",
        "\n",
        "  try:\n",
        "    response=local_llm.invoke([HumanMessage(content=prompt)])\n",
        "    sentiment_score=float(response.strip())\n",
        "    return max(-1, min(1, sentiment_score))\n",
        "  except:\n",
        "    pass\n",
        "  positive_words = [\n",
        "    # Price Movement\n",
        "    'gain', 'gains', 'gained', 'up', 'rise', 'rises', 'rising', 'rose', 'surge', 'surges', 'surging',\n",
        "    'rally', 'rallies', 'rallying', 'rallied', 'jump', 'jumps', 'jumped', 'soar', 'soars', 'soaring',\n",
        "    'climb', 'climbs', 'climbing', 'climbed', 'spike', 'spikes', 'spiked', 'advance', 'advances', 'advancing',\n",
        "    'boost', 'boosts', 'boosted', 'uptick', 'upward', 'upside', 'appreciate', 'appreciation',\n",
        "\n",
        "    # Performance\n",
        "    'profit', 'profits', 'profitable', 'profitability', 'earnings', 'revenue', 'growth', 'growing',\n",
        "    'outperform', 'outperformed', 'outperforming', 'beat', 'beats', 'beating', 'exceed', 'exceeds', 'exceeded',\n",
        "    'strong', 'stronger', 'strength', 'robust', 'solid', 'impressive', 'stellar', 'record',\n",
        "    'improved', 'improvement', 'improving', 'recovery', 'recovering', 'rebound', 'rebounding',\n",
        "\n",
        "    # Market Sentiment\n",
        "    'bull', 'bullish', 'optimistic', 'optimism', 'positive', 'confidence', 'confident',\n",
        "    'momentum', 'breakthrough', 'success', 'successful', 'winning', 'winner',\n",
        "    'opportunity', 'opportunities', 'promising', 'favorable', 'attractive',\n",
        "\n",
        "    # Financial Health\n",
        "    'upgrade', 'upgraded', 'upgrades', 'expansion', 'expanding', 'expand', 'accelerate', 'accelerating',\n",
        "    'innovative', 'innovation', 'milestone', 'achievement', 'accomplished', 'outpace',\n",
        "    'dividend', 'dividends', 'buyback', 'buybacks', 'investment', 'invest',\n",
        "\n",
        "    # Analyst/Institutional\n",
        "    'recommend', 'recommended', 'buy', 'overweight', 'accumulate', 'conviction',\n",
        "    'target', 'upside', 'potential', 'value', 'undervalued', 'bargain',\n",
        "\n",
        "    # General Positive\n",
        "    'high', 'higher', 'highest', 'top', 'best', 'leading', 'leader', 'dominant',\n",
        "    'new high', 'all-time high', 'peak', 'thriving', 'flourishing', 'prosperous'\n",
        "  ]\n",
        "\n",
        "  negative_words = [\n",
        "    # Price Movement\n",
        "    'loss', 'losses', 'lost', 'losing', 'down', 'drop', 'drops', 'dropped', 'dropping',\n",
        "    'fall', 'falls', 'fell', 'falling', 'fallen', 'decline', 'declines', 'declined', 'declining',\n",
        "    'plunge', 'plunges', 'plunged', 'plunging', 'crash', 'crashes', 'crashed', 'crashing',\n",
        "    'tumble', 'tumbles', 'tumbled', 'sink', 'sinks', 'sinking', 'sank', 'slump', 'slumps', 'slumped',\n",
        "    'slide', 'slides', 'sliding', 'dip', 'dips', 'dipped', 'downward', 'downturn', 'downside',\n",
        "    'depreciate', 'depreciation', 'erode', 'erosion',\n",
        "\n",
        "    # Performance\n",
        "    'miss', 'misses', 'missed', 'missing', 'disappoint', 'disappointing', 'disappointed', 'disappointment',\n",
        "    'underperform', 'underperformed', 'underperforming', 'weak', 'weaker', 'weakness', 'poor', 'worse',\n",
        "    'shortfall', 'deficit', 'loss-making', 'unprofitable', 'struggle', 'struggles', 'struggling',\n",
        "    'stagnant', 'stagnation', 'slow', 'slower', 'slowdown', 'decelerate', 'decelerating',\n",
        "\n",
        "    # Market Sentiment\n",
        "    'bear', 'bearish', 'pessimistic', 'pessimism', 'negative', 'concern', 'concerns', 'concerned',\n",
        "    'worry', 'worries', 'worried', 'worrying', 'fear', 'fears', 'fearful', 'panic', 'anxiety',\n",
        "    'uncertain', 'uncertainty', 'doubt', 'doubts', 'skeptical', 'skepticism',\n",
        "    'volatile', 'volatility', 'turbulent', 'turbulence', 'unstable', 'instability',\n",
        "\n",
        "    # Financial Health\n",
        "    'downgrade', 'downgraded', 'downgrades', 'cut', 'cuts', 'cutting', 'reduce', 'reduction',\n",
        "    'layoff', 'layoffs', 'restructuring', 'bankruptcy', 'bankrupt', 'insolvent', 'insolvency',\n",
        "    'debt', 'debts', 'liabilities', 'default', 'defaulted', 'writedown', 'write-down',\n",
        "    'impairment', 'charge', 'charges', 'suspension', 'suspended', 'halt', 'halted',\n",
        "\n",
        "    # Analyst/Institutional\n",
        "    'sell', 'selling', 'sold', 'underweight', 'reduce', 'avoid', 'caution', 'cautious',\n",
        "    'overvalued', 'expensive', 'risky', 'risk', 'risks', 'warning', 'warnings', 'alert',\n",
        "\n",
        "    # Crisis/Problems\n",
        "    'crisis', 'scandal', 'fraud', 'investigation', 'probe', 'lawsuit', 'litigation',\n",
        "    'regulation', 'regulatory', 'fine', 'fines', 'penalty', 'penalties', 'violation',\n",
        "    'delay', 'delays', 'postpone', 'postponed', 'cancel', 'cancelled', 'failure', 'failed',\n",
        "\n",
        "    # General Negative\n",
        "    'low', 'lower', 'lowest', 'bottom', 'worst', 'bad', 'terrible', 'dire', 'grim',\n",
        "    'new low', 'all-time low', 'hemorrhage', 'bleed', 'bleeding', 'collapse', 'collapsing'\n",
        "  ]\n",
        "\n",
        "  intensifiers = [\n",
        "    'very', 'extremely', 'highly', 'significantly', 'substantially', 'considerably',\n",
        "    'dramatically', 'sharply', 'steeply', 'massively', 'hugely', 'greatly'\n",
        "  ]\n",
        "\n",
        "  negations = [\n",
        "    'not', 'no', 'never', 'neither', 'nor', 'none', 'nobody', 'nothing',\n",
        "    'nowhere', 'hardly', 'scarcely', 'barely', \"don't\", \"doesn't\", \"didn't\",\n",
        "    \"won't\", \"wouldn't\", \"shouldn't\", \"cannot\", \"can't\", \"isn't\", \"aren't\", \"wasn't\", \"weren't\"\n",
        "  ]\n",
        "  positive_count = sum(1 for word in text.lower().split() if word in positive_words or 1.5 * word in text.lower().split if word in intensifiers)\n",
        "  negative_count = sum(1 for word in text.lower().split() if word in negative_words or 1.5 * word in text.lower().split if word in negation)\n",
        "  if positive_count + negative_count == 0:\n",
        "    return 0.0\n",
        "  return (positive_count - negative_count) / (positive_count + negative_count)"
      ],
      "metadata": {
        "id": "IYpfw7IE6DpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the heart of the model that connects the model through a RAG pipeline\n",
        "class NewsRAG:\n",
        "  def __init__(self, embedding_model=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
        "    self.llm=local_llm\n",
        "    self.embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=embedding_model\n",
        "    )\n",
        "    self.text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=500,\n",
        "        chunk_overlap=50\n",
        "    )\n",
        "    self.vectorstore = None\n",
        "  def index_news(self, news_articles: List[Dict]):\n",
        "    \"\"\"\n",
        "    news_articles example:\n",
        "    {\n",
        "        \"title\": \"...\",\n",
        "        \"content\": \"...\",\n",
        "        \"link\": \"...\",\n",
        "        \"date\": \"...\",\n",
        "        \"source\": \"...\"\n",
        "    }\n",
        "    \"\"\"\n",
        "    documents = []\n",
        "    for article in news_articles:\n",
        "        content = article.get(\"content\", \"\") or article.get(\"title\", \"\")\n",
        "        header=f\"Source: {article.get('source')}| Date: {article.get('date')}\"\n",
        "        metadata = {\n",
        "            \"title\": article.get(\"title\", \"\"),\n",
        "            \"link\": article.get(\"link\", \"\"),\n",
        "            \"date\": article.get(\"date\", \"\"),\n",
        "            \"source\": article.get(\"source\", \"\")\n",
        "        }\n",
        "\n",
        "        documents.append(\n",
        "            Document(\n",
        "                page_content=content,\n",
        "                metadata=metadata\n",
        "            )\n",
        "        )\n",
        "    if documents:\n",
        "      splits = self.text_splitter.split_documents(documents)\n",
        "      self.vectorstore = Chroma.from_documents(\n",
        "          documents=splits,\n",
        "          embedding=self.embeddings\n",
        "      )\n",
        "\n",
        "  def retrieve_context(self, query: str, k: int = 5) -> List[Dict]:\n",
        "    if self.vectorstore is None:\n",
        "      return []\n",
        "    docs = self.vectorstore.similarity_search(query, k=k)\n",
        "    return self.__distill_context(query, docs)\n",
        "\n",
        "  def __distill_context(self, query: str, docs: List[Document]) -> List[Dict]:\n",
        "    raw_text=\"\\n--\\n\".join([d.page_content for d in docs])\n",
        "    distil_prompts=f\"\"\"\n",
        "        Extract ONLY the facts from the news snippets below that directly answer the query: \"{query}\"\n",
        "        If the snippets are irrelevant, return \"No relevant news found.\"\n",
        "\n",
        "        Snippets:\n",
        "        {raw_text}\n",
        "\n",
        "        Key Facts:\n",
        "        \"\"\"\n",
        "    response=self.llm.invoke([HumanMessage(content=distil_prompts)])\n",
        "    return response.content.strip().split(\"\\n--\\n\")"
      ],
      "metadata": {
        "id": "TzDfoyru7TAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AgentState(TypedDict):\n",
        "    query: str\n",
        "    ticker: str\n",
        "    intent: str\n",
        "    price_data: dict\n",
        "    financial_data: dict\n",
        "    news_articles: Annotated[list, operator.add]\n",
        "    news_context: Annotated[list, operator.add]\n",
        "    sentiment_score: float\n",
        "    analysis: str\n",
        "    recommendation: str\n",
        "    messages: Annotated[List[Any], operator.add]"
      ],
      "metadata": {
        "id": "03-EXbKtcsyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def intent_classifier(state: AgentState):\n",
        "  query=state['query']\n",
        "\n",
        "  query_lower=query.lower()\n",
        "  if any(word in query_lower for word in ['why', 'reason', 'cause']):\n",
        "      intent = 'reason_query'\n",
        "  elif any(word in query_lower for word in ['when', 'trend', 'history']):\n",
        "      intent = 'trend_analysis'\n",
        "  elif any(word in query_lower for word in ['compare', 'vs', 'versus']):\n",
        "      intent = 'comparison'\n",
        "  elif any(word in query_lower for word in ['price', 'cost', 'trading at']):\n",
        "      intent = 'price_query'\n",
        "  else:\n",
        "      intent = 'general'\n",
        "  state['intent']=intent\n",
        "  state['messages'].append(f\"[Intent Classifier] Intent: {intent}\")\n",
        "  return state"
      ],
      "metadata": {
        "id": "-2CCz_-_gIgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_fetcher_node(state: AgentState):\n",
        "    ticker = state['ticker']\n",
        "    if ticker == \"UNKNOWN\":\n",
        "        return {\"messages\": [\"[Fetcher] Error: Could not identify a valid ticker symbol.\"]}\n",
        "\n",
        "    try:\n",
        "        price_data = get_stock_price(ticker)\n",
        "        financial_data = fetch_financial_statements(ticker, 'annual')\n",
        "        return {\n",
        "            \"price_data\": price_data,\n",
        "            \"financial_data\": financial_data,\n",
        "            \"messages\": [f\"[Fetcher] Successfully retrieved data for {ticker}\"]\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"messages\": [f\"[Fetcher] Failed to find {ticker}: {str(e)}\"]}"
      ],
      "metadata": {
        "id": "gPjU8lHBcp8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lock_ticker(state, ticker, source):\n",
        "    # Only skip if we already have a VALID ticker (not empty and not UNKNOWN)\n",
        "    current_ticker = state.get(\"ticker\", \"\")\n",
        "    if current_ticker and current_ticker != \"UNKNOWN\" and current_ticker != \"\":\n",
        "        return state\n",
        "\n",
        "    state[\"ticker\"] = ticker\n",
        "    state.setdefault(\"messages\", []).append(f\"[Ticker Locked] {ticker} by {source}\")\n",
        "    return state"
      ],
      "metadata": {
        "id": "eywiYcHZAlne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def news_researcher_node(state: AgentState):\n",
        "    ticker = state['ticker']\n",
        "    if ticker == \"UNKNOWN\":\n",
        "        return {\"news_articles\": [], \"news_context\": [], \"sentiment_score\": 0.0}\n",
        "    try:\n",
        "        stock = yf.Ticker(ticker)\n",
        "        info = stock.info\n",
        "        company_name = (\n",
        "            info.get('longName') or\n",
        "            info.get('shortName') or\n",
        "            ticker.split('.')[0]\n",
        "        )\n",
        "        core_name = company_name.replace(' Limited', '').replace(' Inc.', '').replace(' Corp.', '').replace(' PLC', '').strip()\n",
        "        search_query = f'\"{core_name}\" stock'\n",
        "    except:\n",
        "        search_query = f\"{ticker.split('.')[0]} stock\"\n",
        "    gn = GNews(max_results=15, language='en', period='7d')\n",
        "    news = gn.get_news(search_query)\n",
        "    if not news:\n",
        "        return {\"news_articles\": [], \"news_context\": [], \"sentiment_score\": 0.0}\n",
        "    filtered_news = []\n",
        "    irrelevant_patterns = ['jewelry heist', 'hockey contract', 'opera', 'highway crash',\n",
        "                          'candy', 'chocolate bar']\n",
        "    for n in news:\n",
        "        title = n.get('title', '')\n",
        "        description = n.get('description', '')\n",
        "        combined = (title + ' ' + description).lower()\n",
        "        if any(pattern in combined for pattern in irrelevant_patterns):\n",
        "            continue\n",
        "        name_words = [word for word in core_name.lower().split() if len(word) > 2]\n",
        "        if name_words and not any(word in combined for word in name_words):\n",
        "            continue\n",
        "        filtered_news.append(n)\n",
        "    if not filtered_news:\n",
        "        filtered_news = news[:5]\n",
        "    distilled_headlines = []\n",
        "    current_char_count = 0\n",
        "    MAX_CHARS = 1500\n",
        "    for n in filtered_news:\n",
        "        headline = n['title']\n",
        "        if current_char_count + len(headline) < MAX_CHARS:\n",
        "            distilled_headlines.append(headline)\n",
        "            current_char_count += len(headline)\n",
        "        else:\n",
        "            break\n",
        "\n",
        "    headlines_str = \" | \".join(distilled_headlines)\n",
        "    sentiment_prompt = f\"Analyze sentiment as positive, negative, or neutral: {headlines_str}. Sentiment:\"\n",
        "\n",
        "    try:\n",
        "        sentiment_label = local_llm.invoke(sentiment_prompt).lower()\n",
        "        score = 0.5 if \"positive\" in sentiment_label else -0.5 if \"negative\" in sentiment_label else 0.0\n",
        "    except:\n",
        "        score = 0.0\n",
        "\n",
        "    return {\n",
        "        \"news_articles\": filtered_news,\n",
        "        \"news_context\": distilled_headlines,\n",
        "        \"sentiment_score\": score,\n",
        "        \"messages\": [f\"[News Researcher] Distilled {len(distilled_headlines)} headlines for local LLM.\"]\n",
        "    }"
      ],
      "metadata": {
        "id": "0s074__UcjVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_exchange(query: str) -> str:\n",
        "    \"\"\"Detect stock exchange from query context\"\"\"\n",
        "    exchange_keywords = {\n",
        "        '.NS': ['india', 'nse', 'bombay', 'mumbai', 'indian', 'bse'],\n",
        "        '.BO': ['bse', 'bombay stock exchange'],\n",
        "        '.HK': ['hong kong', 'hongkong', 'hkex'],\n",
        "        '.L': ['london', 'uk', 'british', 'lse'],\n",
        "        '.T': ['tokyo', 'japan', 'japanese'],\n",
        "        '.AX': ['australia', 'australian', 'asx'],\n",
        "        '.TO': ['toronto', 'canada', 'canadian', 'tsx'],\n",
        "        '.SA': ['brazil', 'brazilian', 'sao paulo'],\n",
        "        '.PA': ['paris', 'france', 'french'],\n",
        "        '.DE': ['germany', 'german', 'frankfurt'],\n",
        "    }\n",
        "\n",
        "    for suffix, keywords in exchange_keywords.items():\n",
        "        if any(keyword in query for keyword in keywords):\n",
        "            return suffix\n",
        "    return ''"
      ],
      "metadata": {
        "id": "3uIMSf9mGjuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyst_node(state: AgentState) -> dict:\n",
        "    # 1. Prepare clean data strings\n",
        "    ticker = state.get('ticker', 'UNKNOWN')\n",
        "    # Truncate news context to stay under local 512-token limit\n",
        "    distilled_news = \" | \".join(state.get('news_context', []))[:1200]\n",
        "\n",
        "    context_package = {\n",
        "        \"ticker\": ticker,\n",
        "        \"price\": state.get('price_data', {}).get('current_price', 'N/A'),\n",
        "        \"sentiment\": f\"{state.get('sentiment_score', 0.0):.2f}\",\n",
        "        \"news\": distilled_news\n",
        "    }\n",
        "\n",
        "    prompt = f\"\"\"Task: Financial Analysis.\n",
        "    Context: {json.dumps(context_package)}\n",
        "    Query: {state['query']}\n",
        "\n",
        "    Instructions: Provide 3-4 sentences on current status and news impact.\n",
        "    Analysis:\"\"\"\n",
        "\n",
        "    updates = {}\n",
        "\n",
        "    try:\n",
        "        # --- PRIMARY: Intelligent LLM (Gemini) ---\n",
        "        # Note: 'llm' should be your ChatGoogleGenerativeAI instance\n",
        "        response = llm.invoke([HumanMessage(content=prompt)])\n",
        "        updates['analysis'] = response.content.strip()\n",
        "        updates['messages'] = [\"[Analyst] Analysis completed using Gemini\"]\n",
        "\n",
        "    except Exception as e:\n",
        "        # --- FALLBACK: Local LLM (Flan-T5) ---\n",
        "        error_msg = str(e)[:50]\n",
        "        updates['messages'] = [f\"[Analyst] Gemini Quota Hit ({error_msg}), switching to local\"]\n",
        "\n",
        "        try:\n",
        "            # We use a shorter prompt for the local model to prevent repetition loops\n",
        "            local_prompt = f\"Summarize {ticker} stock status: Price {context_package['price']}, News: {distilled_news}. Summary:\"\n",
        "            response = local_llm.invoke(local_prompt)\n",
        "\n",
        "            # Clean local output to prevent common Flan-T5 loops\n",
        "            final_text = response.strip() if isinstance(response, str) else str(response)\n",
        "            updates['analysis'] = final_text.split(\"Summary:\")[-1].strip()\n",
        "            updates['messages'].append(\"[Analyst] Analysis completed using local LLM\")\n",
        "\n",
        "        except Exception as local_e:\n",
        "            updates['analysis'] = \"Deep analysis unavailable. Please check the dashboard metrics above.\"\n",
        "            updates['messages'].append(f\"[Analyst] Local Fallback failed: {str(local_e)[:50]}\")\n",
        "\n",
        "    return updates"
      ],
      "metadata": {
        "id": "W5fvG6w4qJPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_ticker_cache={}\n",
        "def ticker_extractor(query: str):\n",
        "    \"\"\"Enhanced ticker extraction with better NLP and company name recognition\"\"\"\n",
        "    try:\n",
        "        query_lower = query.lower()\n",
        "        query_original = query  # Keep original for ticker symbol detection\n",
        "\n",
        "        # Check cache first\n",
        "        cache_key = query_lower.strip()\n",
        "        if cache_key in _ticker_cache:\n",
        "            print(f\"[DEBUG] Ticker from cache: {_ticker_cache[cache_key]}\")\n",
        "            return _ticker_cache[cache_key]\n",
        "\n",
        "        # STEP 1: Enhanced common stock mappings\n",
        "        common_stocks = {\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡ºðŸ‡¸ USA â€“ Tech, Finance, Industry\n",
        "    # =========================\n",
        "    'apple': 'AAPL',\n",
        "    'microsoft': 'MSFT',\n",
        "    'amazon': 'AMZN',\n",
        "    'google': 'GOOGL',\n",
        "    'alphabet': 'GOOGL',\n",
        "    'meta': 'META',\n",
        "    'facebook': 'META',\n",
        "    'tesla': 'TSLA',\n",
        "    'nvidia': 'NVDA',\n",
        "    'netflix': 'NFLX',\n",
        "    'intel': 'INTC',\n",
        "    'amd': 'AMD',\n",
        "    'qualcomm': 'QCOM',\n",
        "    'oracle': 'ORCL',\n",
        "    'ibm': 'IBM',\n",
        "    'salesforce': 'CRM',\n",
        "    'adobe': 'ADBE',\n",
        "    'paypal': 'PYPL',\n",
        "    'visa': 'V',\n",
        "    'mastercard': 'MA',\n",
        "    'jpmorgan': 'JPM',\n",
        "    'goldman sachs': 'GS',\n",
        "    'bank of america': 'BAC',\n",
        "    'morgan stanley': 'MS',\n",
        "    'wells fargo': 'WFC',\n",
        "    'coca cola': 'KO',\n",
        "    'pepsi': 'PEP',\n",
        "    'walmart': 'WMT',\n",
        "    'costco': 'COST',\n",
        "    'target': 'TGT',\n",
        "    'boeing': 'BA',\n",
        "    'lockheed martin': 'LMT',\n",
        "    'general electric': 'GE',\n",
        "    'ford': 'F',\n",
        "    'general motors': 'GM',\n",
        "    'exxon': 'XOM',\n",
        "    'chevron': 'CVX',\n",
        "\n",
        "    # Tech additions\n",
        "    'broadcom': 'AVGO',\n",
        "    'cisco': 'CSCO',\n",
        "    'uber': 'UBER',\n",
        "    'lyft': 'LYFT',\n",
        "    'airbnb': 'ABNB',\n",
        "    'snowflake': 'SNOW',\n",
        "    'palantir': 'PLTR',\n",
        "    'coinbase': 'COIN',\n",
        "    'roblox': 'RBLX',\n",
        "    'spotify': 'SPOT',\n",
        "    'zoom': 'ZM',\n",
        "    'doordash': 'DASH',\n",
        "    'shopify': 'SHOP',\n",
        "    'square': 'SQ',\n",
        "    'block': 'SQ',\n",
        "    'twilio': 'TWLO',\n",
        "    'datadog': 'DDOG',\n",
        "    'crowdstrike': 'CRWD',\n",
        "    'servicenow': 'NOW',\n",
        "    'workday': 'WDAY',\n",
        "    'splunk': 'SPLK',\n",
        "    'mongodb': 'MDB',\n",
        "    'okta': 'OKTA',\n",
        "    'gitlab': 'GTLB',\n",
        "    'asana': 'ASAN',\n",
        "    'dropbox': 'DBX',\n",
        "    'atlassian': 'TEAM',\n",
        "    'dell': 'DELL',\n",
        "    'hp': 'HPQ',\n",
        "    'micron': 'MU',\n",
        "    'applied materials': 'AMAT',\n",
        "    'lam research': 'LRCX',\n",
        "    'synopsys': 'SNPS',\n",
        "    'cadence': 'CDNS',\n",
        "    'marvell': 'MRVL',\n",
        "    'arista': 'ANET',\n",
        "    'fortinet': 'FTNT',\n",
        "    'palo alto': 'PANW',\n",
        "\n",
        "    # Finance additions\n",
        "    'citigroup': 'C',\n",
        "    'charles schwab': 'SCHW',\n",
        "    'blackrock': 'BLK',\n",
        "    'american express': 'AXP',\n",
        "    'capital one': 'COF',\n",
        "    'discover': 'DFS',\n",
        "    'us bancorp': 'USB',\n",
        "    'pnc': 'PNC',\n",
        "    'truist': 'TFC',\n",
        "    'bank of ny mellon': 'BK',\n",
        "    'state street': 'STT',\n",
        "    'synchrony': 'SYF',\n",
        "    'ally financial': 'ALLY',\n",
        "    'robinhood': 'HOOD',\n",
        "\n",
        "    # Healthcare & Pharma\n",
        "    'johnson & johnson': 'JNJ',\n",
        "    'jnj': 'JNJ',\n",
        "    'pfizer': 'PFE',\n",
        "    'merck': 'MRK',\n",
        "    'abbvie': 'ABBV',\n",
        "    'eli lilly': 'LLY',\n",
        "    'bristol myers': 'BMY',\n",
        "    'amgen': 'AMGN',\n",
        "    'gilead': 'GILD',\n",
        "    'moderna': 'MRNA',\n",
        "    'regeneron': 'REGN',\n",
        "    'biogen': 'BIIB',\n",
        "    'vertex': 'VRTX',\n",
        "    'illumina': 'ILMN',\n",
        "    'unitedhealth': 'UNH',\n",
        "    'cvs': 'CVS',\n",
        "    'humana': 'HUM',\n",
        "    'cigna': 'CI',\n",
        "    'anthem': 'ELV',\n",
        "    'mckesson': 'MCK',\n",
        "    'cardinal health': 'CAH',\n",
        "    'walgreens': 'WBA',\n",
        "    'thermo fisher': 'TMO',\n",
        "    'danaher': 'DHR',\n",
        "    'abbott': 'ABT',\n",
        "    'medtronic': 'MDT',\n",
        "    'intuitive surgical': 'ISRG',\n",
        "    'stryker': 'SYK',\n",
        "    'boston scientific': 'BSX',\n",
        "    'edwards lifesciences': 'EW',\n",
        "\n",
        "    # Consumer & Retail\n",
        "    'procter & gamble': 'PG',\n",
        "    'nike': 'NKE',\n",
        "    'starbucks': 'SBUX',\n",
        "    'mcdonalds': 'MCD',\n",
        "    'chipotle': 'CMG',\n",
        "    'yum brands': 'YUM',\n",
        "    'home depot': 'HD',\n",
        "    'lowes': 'LOW',\n",
        "    'tjx': 'TJX',\n",
        "    'ross stores': 'ROST',\n",
        "    'dollar general': 'DG',\n",
        "    'dollar tree': 'DLTR',\n",
        "    'best buy': 'BBY',\n",
        "    'gap': 'GPS',\n",
        "    'lululemon': 'LULU',\n",
        "    'ulta': 'ULTA',\n",
        "    'estee lauder': 'EL',\n",
        "    'colgate': 'CL',\n",
        "    'kimberly clark': 'KMB',\n",
        "    'general mills': 'GIS',\n",
        "    'kellogg': 'K',\n",
        "    'kraft heinz': 'KHC',\n",
        "    'mondelez': 'MDLZ',\n",
        "    'hershey': 'HSY',\n",
        "    'constellation brands': 'STZ',\n",
        "    'molson coors': 'TAP',\n",
        "    'anheuser busch': 'BUD',\n",
        "    'philip morris': 'PM',\n",
        "    'altria': 'MO',\n",
        "\n",
        "    # Industrial & Manufacturing\n",
        "    'caterpillar': 'CAT',\n",
        "    'deere': 'DE',\n",
        "    '3m': 'MMM',\n",
        "    'honeywell': 'HON',\n",
        "    'united technologies': 'RTX',\n",
        "    'raytheon': 'RTX',\n",
        "    'northrop grumman': 'NOC',\n",
        "    'general dynamics': 'GD',\n",
        "    'union pacific': 'UNP',\n",
        "    'norfolk southern': 'NSC',\n",
        "    'csx': 'CSX',\n",
        "    'fedex': 'FDX',\n",
        "    'ups': 'UPS',\n",
        "    'delta': 'DAL',\n",
        "    'united airlines': 'UAL',\n",
        "    'american airlines': 'AAL',\n",
        "    'southwest': 'LUV',\n",
        "\n",
        "    # Energy & Utilities\n",
        "    'conocophillips': 'COP',\n",
        "    'schlumberger': 'SLB',\n",
        "    'halliburton': 'HAL',\n",
        "    'occidental': 'OXY',\n",
        "    'marathon': 'MPC',\n",
        "    'valero': 'VLO',\n",
        "    'phillips 66': 'PSX',\n",
        "    'duke energy': 'DUK',\n",
        "    'southern company': 'SO',\n",
        "    'nextera': 'NEE',\n",
        "    'dominion': 'D',\n",
        "    'exelon': 'EXC',\n",
        "    'first solar': 'FSLR',\n",
        "    'enphase': 'ENPH',\n",
        "    'sunrun': 'RUN',\n",
        "    'plug power': 'PLUG',\n",
        "    'bloom energy': 'BE',\n",
        "\n",
        "    # Telecom & Media\n",
        "    'verizon': 'VZ',\n",
        "    'at&t': 'T',\n",
        "    't-mobile': 'TMUS',\n",
        "    'comcast': 'CMCSA',\n",
        "    'charter': 'CHTR',\n",
        "    'dish': 'DISH',\n",
        "    'disney': 'DIS',\n",
        "    'warner bros': 'WBD',\n",
        "    'paramount': 'PARA',\n",
        "    'fox': 'FOX',\n",
        "    'new york times': 'NYT',\n",
        "\n",
        "    # Real Estate & REITs\n",
        "    'american tower': 'AMT',\n",
        "    'crown castle': 'CCI',\n",
        "    'prologis': 'PLD',\n",
        "    'equinix': 'EQIX',\n",
        "    'digital realty': 'DLR',\n",
        "    'simon property': 'SPG',\n",
        "    'realty income': 'O',\n",
        "    'welltower': 'WELL',\n",
        "    'avalonbay': 'AVB',\n",
        "    'equity residential': 'EQR',\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¨ðŸ‡³ China / ðŸ‡­ðŸ‡° Hong Kong\n",
        "    # =========================\n",
        "    'alibaba': '9988.HK',\n",
        "    'baba': '9988.HK',\n",
        "    'tencent': '0700.HK',\n",
        "    'baidu': 'BIDU',\n",
        "    'jd': 'JD',\n",
        "    'jd.com': 'JD',\n",
        "    'meituan': '3690.HK',\n",
        "    'ping an': '2318.HK',\n",
        "    'byd': '1211.HK',\n",
        "    'nio': 'NIO',\n",
        "    'xpeng': 'XPEV',\n",
        "    'li auto': 'LI',\n",
        "    'china mobile': '0941.HK',\n",
        "    'china telecom': '0728.HK',\n",
        "    'china unicom': '0762.HK',\n",
        "    'lenovo': '0992.HK',\n",
        "    'haier': '6690.HK',\n",
        "\n",
        "    # China additions\n",
        "    'pinduoduo': 'PDD',\n",
        "    'netease': 'NTES',\n",
        "    'trip.com': 'TCOM',\n",
        "    'bilibili': 'BILI',\n",
        "    'kuaishou': '1024.HK',\n",
        "    'xiaomi': '1810.HK',\n",
        "    'geely': '0175.HK',\n",
        "    'great wall': '2333.HK',\n",
        "    'china construction bank': '0939.HK',\n",
        "    'icbc': '1398.HK',\n",
        "    'bank of china': '3988.HK',\n",
        "    'agricultural bank': '1288.HK',\n",
        "    'china merchants bank': '3968.HK',\n",
        "    'petrochina': '0857.HK',\n",
        "    'sinopec': '0386.HK',\n",
        "    'cnooc': '0883.HK',\n",
        "    'anta': '2020.HK',\n",
        "    'li ning': '2331.HK',\n",
        "    'wuxi biologics': '2269.HK',\n",
        "    'contemporary amperex': '300750.SZ',\n",
        "    'catl': '300750.SZ',\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡®ðŸ‡³ India â€“ NIFTY / Large Caps\n",
        "    # =========================\n",
        "    'reliance': 'RELIANCE.NS',\n",
        "    'reliance industries': 'RELIANCE.NS',\n",
        "    'tcs': 'TCS.NS',\n",
        "    'infosys': 'INFY.NS',\n",
        "    'wipro': 'WIPRO.NS',\n",
        "    'hdfc bank': 'HDFCBANK.NS',\n",
        "    'icici bank': 'ICICIBANK.NS',\n",
        "    'axis bank': 'AXISBANK.NS',\n",
        "    'state bank': 'SBIN.NS',\n",
        "    'sbi': 'SBIN.NS',\n",
        "    'kotak bank': 'KOTAKBANK.NS',\n",
        "    'bharti airtel': 'BHARTIARTL.NS',\n",
        "    'airtel': 'BHARTIARTL.NS',\n",
        "    'itc': 'ITC.NS',\n",
        "    'l&t': 'LT.NS',\n",
        "    'mahindra': 'M&M.NS',\n",
        "    'tata motors': 'TATAMOTORS.NS',\n",
        "    'tata steel': 'TATASTEEL.NS',\n",
        "    'maruti': 'MARUTI.NS',\n",
        "    'sun pharma': 'SUNPHARMA.NS',\n",
        "    'dr reddy': 'DRREDDY.NS',\n",
        "    'adani ports': 'ADANIPORTS.NS',\n",
        "    'adani enterprises': 'ADANIENT.NS',\n",
        "    'adani power': 'ADANIPOWER.NS',\n",
        "\n",
        "    # India additions\n",
        "    'hcl tech': 'HCLTECH.NS',\n",
        "    'tech mahindra': 'TECHM.NS',\n",
        "    'bajaj finance': 'BAJFINANCE.NS',\n",
        "    'bajaj finserv': 'BAJAJFINSV.NS',\n",
        "    'hdfc life': 'HDFCLIFE.NS',\n",
        "    'sbi life': 'SBILIFE.NS',\n",
        "    'indusind bank': 'INDUSINDBK.NS',\n",
        "    'bandhan bank': 'BANDHANBNK.NS',\n",
        "    'jio': 'RELIANCE.NS',  # Part of Reliance\n",
        "    'hindustan unilever': 'HINDUNILVR.NS',\n",
        "    'hul': 'HINDUNILVR.NS',\n",
        "    'asian paints': 'ASIANPAINT.NS',\n",
        "    'nestle india': 'NESTLEIND.NS',\n",
        "    'britannia': 'BRITANNIA.NS',\n",
        "    'dabur': 'DABUR.NS',\n",
        "    'titan': 'TITAN.NS',\n",
        "    'bajaj auto': 'BAJAJ-AUTO.NS',\n",
        "    'hero motocorp': 'HEROMOTOCO.NS',\n",
        "    'ultratech cement': 'ULTRACEMCO.NS',\n",
        "    'grasim': 'GRASIM.NS',\n",
        "    'jsw steel': 'JSWSTEEL.NS',\n",
        "    'hindalco': 'HINDALCO.NS',\n",
        "    'vedanta': 'VEDL.NS',\n",
        "    'coal india': 'COALINDIA.NS',\n",
        "    'ntpc': 'NTPC.NS',\n",
        "    'power grid': 'POWERGRID.NS',\n",
        "    'ongc': 'ONGC.NS',\n",
        "    'ioc': 'IOC.NS',\n",
        "    'bpcl': 'BPCL.NS',\n",
        "    'cipla': 'CIPLA.NS',\n",
        "    'divis lab': 'DIVISLAB.NS',\n",
        "    'biocon': 'BIOCON.NS',\n",
        "    'apollo hospitals': 'APOLLOHOSP.NS',\n",
        "    'dmart': 'DMART.NS',\n",
        "    'zomato': 'ZOMATO.NS',\n",
        "    'paytm': 'PAYTM.NS',\n",
        "    'nykaa': 'NYKAA.NS',\n",
        "    'policybazaar': 'POLICYBZR.NS',\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¯ðŸ‡µ Japan\n",
        "    # =========================\n",
        "    'toyota': '7203.T',\n",
        "    'sony': '6758.T',\n",
        "    'nintendo': '7974.T',\n",
        "    'softbank': '9984.T',\n",
        "    'mitsubishi': '8058.T',\n",
        "    'hitachi': '6501.T',\n",
        "    'panasonic': '6752.T',\n",
        "    'canon': '7751.T',\n",
        "\n",
        "    # Japan additions\n",
        "    'honda': '7267.T',\n",
        "    'nissan': '7201.T',\n",
        "    'mazda': '7261.T',\n",
        "    'subaru': '7270.T',\n",
        "    'suzuki': '7269.T',\n",
        "    'bridgestone': '5108.T',\n",
        "    'keyence': '6861.T',\n",
        "    'fanuc': '6954.T',\n",
        "    'murata': '6981.T',\n",
        "    'tokyo electron': '8035.T',\n",
        "    'daikin': '6367.T',\n",
        "    'recruit': '6098.T',\n",
        "    'kddi': '9433.T',\n",
        "    'ntt': '9432.T',\n",
        "    'ntt docomo': '9437.T',\n",
        "    'rakuten': '4755.T',\n",
        "    'z holdings': '4689.T',\n",
        "    'yahoo japan': '4689.T',\n",
        "    'bandai namco': '7832.T',\n",
        "    'capcom': '9697.T',\n",
        "    'konami': '9766.T',\n",
        "    'square enix': '9684.T',\n",
        "    'fast retailing': '9983.T',\n",
        "    'uniqlo': '9983.T',\n",
        "    'seven & i': '3382.T',\n",
        "    'lawson': '2651.T',\n",
        "    'aeon': '8267.T',\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡°ðŸ‡· South Korea\n",
        "    # =========================\n",
        "    'samsung': '005930.KS',\n",
        "    'samsung electronics': '005930.KS',\n",
        "    'hyundai': '005380.KS',\n",
        "    'kia': '000270.KS',\n",
        "    'lg electronics': '066570.KS',\n",
        "    'sk hynix': '000660.KS',\n",
        "    'naver': '035420.KS',\n",
        "    'kakao': '035720.KS',\n",
        "\n",
        "    # South Korea additions\n",
        "    'samsung biologics': '207940.KS',\n",
        "    'samsung sdi': '006400.KS',\n",
        "    'lg chem': '051910.KS',\n",
        "    'lg energy': '373220.KS',\n",
        "    'posco': '005490.KS',\n",
        "    'sk innovation': '096770.KS',\n",
        "    'celltrion': '068270.KS',\n",
        "    'amorepacific': '090430.KS',\n",
        "    'korean air': '003490.KS',\n",
        "    'hybe': '352820.KS',\n",
        "    'bts': '352820.KS',  # HYBE\n",
        "    'sm entertainment': '041510.KS',\n",
        "    'jyp': '035900.KS',\n",
        "    'yg': '122870.KS',\n",
        "    'ncsoft': '036570.KS',\n",
        "    'netmarble': '251270.KS',\n",
        "    'coupang': 'CPNG',  # Listed in US\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡ªðŸ‡º Europe\n",
        "    # =========================\n",
        "    'nestle': 'NESN.SW',\n",
        "    'roche': 'ROG.SW',\n",
        "    'novartis': 'NOVN.SW',\n",
        "    'lvmh': 'MC.PA',\n",
        "    'airbus': 'AIR.PA',\n",
        "    'totalenergies': 'TTE.PA',\n",
        "    'sap': 'SAP.DE',\n",
        "    'siemens': 'SIE.DE',\n",
        "    'bmw': 'BMW.DE',\n",
        "    'volkswagen': 'VOW3.DE',\n",
        "    'mercedes': 'MBG.DE',\n",
        "    'allianz': 'ALV.DE',\n",
        "    'unilever': 'ULVR.L',\n",
        "    'bp': 'BP.L',\n",
        "    'shell': 'SHEL.L',\n",
        "    'hsbc': 'HSBA.L',\n",
        "    'barclays': 'BARC.L',\n",
        "\n",
        "    # Europe additions - France\n",
        "    'loreal': 'OR.PA',\n",
        "    'hermes': 'RMS.PA',\n",
        "    'sanofi': 'SAN.PA',\n",
        "    'bnp paribas': 'BNP.PA',\n",
        "    'axa': 'CS.PA',\n",
        "    'danone': 'BN.PA',\n",
        "    'schneider': 'SU.PA',\n",
        "    'vinci': 'DG.PA',\n",
        "    'pernod ricard': 'RI.PA',\n",
        "    'carrefour': 'CA.PA',\n",
        "    'renault': 'RNO.PA',\n",
        "    'publicis': 'PUB.PA',\n",
        "    'kering': 'KER.PA',\n",
        "    'dior': 'CDI.PA',\n",
        "\n",
        "    # Germany\n",
        "    'basf': 'BAS.DE',\n",
        "    'bayer': 'BAYN.DE',\n",
        "    'deutsche bank': 'DBK.DE',\n",
        "    'commerzbank': 'CBK.DE',\n",
        "    'deutsche telekom': 'DTE.DE',\n",
        "    'adidas': 'ADS.DE',\n",
        "    'porsche': 'P911.DE',\n",
        "    'continental': 'CON.DE',\n",
        "    'infineon': 'IFX.DE',\n",
        "    'henkel': 'HEN3.DE',\n",
        "    'eon': 'EOAN.DE',\n",
        "    'rwe': 'RWE.DE',\n",
        "    'deutsche post': 'DPW.DE',\n",
        "    'lufthansa': 'LHA.DE',\n",
        "\n",
        "    # UK\n",
        "    'astrazeneca': 'AZN.L',\n",
        "    'glaxosmithkline': 'GSK.L',\n",
        "    'gsk': 'GSK.L',\n",
        "    'diageo': 'DGE.L',\n",
        "    'british american tobacco': 'BATS.L',\n",
        "    'rio tinto': 'RIO.L',\n",
        "    'glencore': 'GLEN.L',\n",
        "    'anglo american': 'AAL.L',\n",
        "    'bhp': 'BHP.L',\n",
        "    'vodafone': 'VOD.L',\n",
        "    'bt group': 'BT-A.L',\n",
        "    'rolls royce': 'RR.L',\n",
        "    'national grid': 'NG.L',\n",
        "    'prudential': 'PRU.L',\n",
        "    'aviva': 'AV.L',\n",
        "    'lloyds': 'LLOY.L',\n",
        "    'standard chartered': 'STAN.L',\n",
        "    'tesco': 'TSCO.L',\n",
        "    'marks & spencer': 'MKS.L',\n",
        "    'burberry': 'BRBY.L',\n",
        "\n",
        "    # Switzerland\n",
        "    'ubs': 'UBSG.SW',\n",
        "    'credit suisse': 'CSGN.SW',\n",
        "    'zurich insurance': 'ZURN.SW',\n",
        "    'abb': 'ABBN.SW',\n",
        "    'lonza': 'LONN.SW',\n",
        "    'richemont': 'CFR.SW',\n",
        "    'swatch': 'UHR.SW',\n",
        "    'givaudan': 'GIVN.SW',\n",
        "    'holcim': 'HOLN.SW',\n",
        "\n",
        "    # Netherlands\n",
        "    'asml': 'ASML.AS',\n",
        "    'ing': 'INGA.AS',\n",
        "    'heineken': 'HEIA.AS',\n",
        "    'philips': 'PHIA.AS',\n",
        "    'adyen': 'ADYEN.AS',\n",
        "    'shell netherlands': 'SHEL.AS',\n",
        "\n",
        "    # Spain\n",
        "    'santander': 'SAN.MC',\n",
        "    'bbva': 'BBVA.MC',\n",
        "    'iberdrola': 'IBE.MC',\n",
        "    'inditex': 'ITX.MC',\n",
        "    'zara': 'ITX.MC',\n",
        "    'telefonica': 'TEF.MC',\n",
        "    'repsol': 'REP.MC',\n",
        "\n",
        "    # Italy\n",
        "    'ferrari': 'RACE.MI',\n",
        "    'eni': 'ENI.MI',\n",
        "    'enel': 'ENEL.MI',\n",
        "    'intesa sanpaolo': 'ISP.MI',\n",
        "    'unicredit': 'UCG.MI',\n",
        "    'stellantis': 'STLA.MI',\n",
        "    'prada': '1913.HK',\n",
        "    'moncler': 'MONC.MI',\n",
        "\n",
        "    # Nordic\n",
        "    'novo nordisk': 'NOVO-B.CO',\n",
        "    'vestas': 'VWS.CO',\n",
        "    'orsted': 'ORSTED.CO',\n",
        "    'h&m': 'HM-B.ST',\n",
        "    'ericsson': 'ERIC-B.ST',\n",
        "    'volvo': 'VOLV-B.ST',\n",
        "    'spotify sweden': 'SPOT',  # Listed in US\n",
        "    'nokia': 'NOKIA.HE',\n",
        "    'nordea': 'NDA-FI.HE',\n",
        "    'equinor': 'EQNR.OL',\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¨ðŸ‡¦ Canada\n",
        "    # =========================\n",
        "    'shopify': 'SHOP.TO',\n",
        "    'royal bank': 'RY.TO',\n",
        "    'td bank': 'TD.TO',\n",
        "    'enbridge': 'ENB.TO',\n",
        "\n",
        "    # Canada additions\n",
        "    'bmo': 'BMO.TO',\n",
        "    'scotiabank': 'BNS.TO',\n",
        "    'cbc': 'CM.TO',\n",
        "    'national bank': 'NA.TO',\n",
        "    'manulife': 'MFC.TO',\n",
        "    'sun life': 'SLF.TO',\n",
        "    'brookfield': 'BN.TO',\n",
        "    'canadian pacific': 'CP.TO',\n",
        "    'cn rail': 'CNR.TO',\n",
        "    'suncor': 'SU.TO',\n",
        "    'canadian natural': 'CNQ.TO',\n",
        "    'tc energy': 'TRP.TO',\n",
        "    'barrick gold': 'ABX.TO',\n",
        "    'nutrien': 'NTR.TO',\n",
        "    'magna': 'MG.TO',\n",
        "    'telus': 'T.TO',\n",
        "    'rogers': 'RCI-B.TO',\n",
        "    'bce': 'BCE.TO',\n",
        "    'alimentation couche': 'ATD.TO',\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡§ðŸ‡· Brazil\n",
        "    # =========================\n",
        "    'petrobras': 'PETR4.SA',\n",
        "    'vale': 'VALE3.SA',\n",
        "    'itau': 'ITUB4.SA',\n",
        "\n",
        "    # Brazil additions\n",
        "    'bradesco': 'BBDC4.SA',\n",
        "    'banco do brasil': 'BBAS3.SA',\n",
        "    'ambev': 'ABEV3.SA',\n",
        "    'jbs': 'JBSS3.SA',\n",
        "    'weg': 'WEGE3.SA',\n",
        "    'suzano': 'SUZB3.SA',\n",
        "    'natura': 'NTCO3.SA',\n",
        "    'magazine luiza': 'MGLU3.SA',\n",
        "    'b3': 'B3SA3.SA',\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¸ðŸ‡¦ Middle East\n",
        "    # =========================\n",
        "    'aramco': '2222.SR',\n",
        "    'saudi aramco': '2222.SR',\n",
        "\n",
        "    # Middle East additions\n",
        "    'sabic': '2010.SR',\n",
        "    'al rajhi': '1120.SR',\n",
        "    'stc': '7010.SR',\n",
        "    'maaden': '1211.SR',\n",
        "    'emaar': 'EMAAR.DU',\n",
        "    'dubai islamic': 'DIB.DU',\n",
        "    'etisalat': 'ETISALAT.AD',\n",
        "    'adnoc': '2222.SR',  # Part of ecosystem\n",
        "\n",
        "    # Israel\n",
        "    'teva': 'TEVA',\n",
        "    'check point': 'CHKP',\n",
        "    'nice': 'NICE',\n",
        "    'wix': 'WIX',\n",
        "    'monday.com': 'MNDY',\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¦ðŸ‡º Australia\n",
        "    # =========================\n",
        "    'bhp australia': 'BHP.AX',\n",
        "    'cba': 'CBA.AX',\n",
        "    'commonwealth bank': 'CBA.AX',\n",
        "    'westpac': 'WBC.AX',\n",
        "    'anz': 'ANZ.AX',\n",
        "    'nab': 'NAB.AX',\n",
        "    'csl': 'CSL.AX',\n",
        "    'woolworths': 'WOW.AX',\n",
        "    'wesfarmers': 'WES.AX',\n",
        "    'telstra': 'TLS.AX',\n",
        "    'fortescue': 'FMG.AX',\n",
        "    'macquarie': 'MQG.AX',\n",
        "    'rio tinto australia': 'RIO.AX',\n",
        "    'woodside': 'WDS.AX',\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡²ðŸ‡½ Mexico\n",
        "    # =========================\n",
        "    'america movil': 'AMX',\n",
        "    'femsa': 'FMX',\n",
        "    'walmart mexico': 'WALMEX.MX',\n",
        "    'grupo mexico': 'GMEXICOB.MX',\n",
        "    'cemex': 'CX',\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¦ðŸ‡· Argentina\n",
        "    # =========================\n",
        "    'mercadolibre': 'MELI',\n",
        "    'globant': 'GLOB',\n",
        "    'ypf': 'YPF',\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¿ðŸ‡¦ South Africa\n",
        "    # =========================\n",
        "    'naspers': 'NPN.JO',\n",
        "    'prosus': 'PRX.AS',\n",
        "    'mtn': 'MTN.JO',\n",
        "    'shoprite': 'SHP.JO',\n",
        "    'anglogold': 'ANG.JO',\n",
        "    'gold fields': 'GFI.JO',\n",
        "    'sasol': 'SOL.JO',\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¸ðŸ‡¬ Singapore\n",
        "    # =========================\n",
        "    'dbs': 'D05.SI',\n",
        "    'ocbc': 'O39.SI',\n",
        "    'uob': 'U11.SI',\n",
        "    'singtel': 'Z74.SI',\n",
        "    'sea limited': 'SE',  # Listed in US\n",
        "    'grab': 'GRAB',  # Listed in US\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¹ðŸ‡¼ Taiwan\n",
        "    # =========================\n",
        "    'tsmc': 'TSM',\n",
        "    'taiwan semiconductor': 'TSM',\n",
        "    'hon hai': '2317.TW',\n",
        "    'foxconn': '2317.TW',\n",
        "    'mediatek': '2454.TW',\n",
        "    'delta electronics': '2308.TW',\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡®ðŸ‡© Indonesia\n",
        "    # =========================\n",
        "    'bank central asia': 'BBCA.JK',\n",
        "    'bank rakyat': 'BBRI.JK',\n",
        "    'bank mandiri': 'BMRI.JK',\n",
        "    'telkom indonesia': 'TLKM.JK',\n",
        "    'indofood': 'INDF.JK',\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¹ðŸ‡­ Thailand\n",
        "    # =========================\n",
        "    'ptÑ‚': 'PTT.BK',\n",
        "    'cp all': 'CPALL.BK',\n",
        "    'advanced info': 'ADVANC.BK',\n",
        "    'scb': 'SCB.BK',\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡µðŸ‡­ Philippines\n",
        "    # =========================\n",
        "    'sm investments': 'SM.PS',\n",
        "    'ayala': 'AC.PS',\n",
        "    'bdo': 'BDO.PS',\n",
        "    'jollibee': 'JFC.PS',\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡»ðŸ‡³ Vietnam\n",
        "    # =========================\n",
        "    'vingroup': 'VIC.VN',\n",
        "    'vinhomes': 'VHM.VN',\n",
        "    'vinamilk': 'VNM.VN',\n",
        "    'masan': 'MSN.VN',\n",
        "    }\n",
        "        # Check for EXACT company name matches (longest match first)\n",
        "        sorted_companies = sorted(common_stocks.keys(), key=len, reverse=True)\n",
        "        for company in sorted_companies:\n",
        "            # Use word boundaries to avoid partial matches\n",
        "            if re.search(r'\\b' + re.escape(company) + r'\\b', query_lower):\n",
        "                ticker = common_stocks[company]\n",
        "                print(f\"[DEBUG] STEP 1 (Common Stock) matched '{company}', returning '{ticker}'\")\n",
        "                _ticker_cache[cache_key] = ticker\n",
        "                return ticker\n",
        "\n",
        "        # STEP 2: Check for explicit ticker symbols ONLY at word boundaries\n",
        "        # Must be isolated or preceded by $ or space\n",
        "        ticker_pattern = re.search(r'(?:^|\\s|\\$)([A-Z]{2,5})(?:\\s|$|\\.)', query_original)\n",
        "        if ticker_pattern:\n",
        "            potential_ticker = ticker_pattern.group(1)\n",
        "            # Avoid common words\n",
        "            if potential_ticker not in ['THE', 'AND', 'FOR', 'STOCK', 'PRICE', 'INDIA', 'HONG', 'KONG']:\n",
        "                print(f\"[DEBUG] STEP 2 (Explicit Ticker) potential: {potential_ticker}\")\n",
        "                validated = validate_ticker(potential_ticker)\n",
        "                if validated:\n",
        "                    print(f\"[DEBUG] STEP 2 (Explicit Ticker) validated: {validated}\")\n",
        "                    _ticker_cache[cache_key] = validated\n",
        "                    return validated\n",
        "\n",
        "        # STEP 3: Extract company name from conversational query\n",
        "        # Patterns like \"company stock\" or \"company india\"\n",
        "        company_patterns = [\n",
        "            r'\\b([a-z]+(?:\\s+[a-z]+)*)\\s+(?:stock|share|equity|industries)',\n",
        "            r'\\b([a-z]+(?:\\s+[a-z]+)*)\\s+(?:india|china|hong\\s+kong|usa)',\n",
        "        ]\n",
        "\n",
        "        company_name = None\n",
        "        for pattern in company_patterns:\n",
        "            match = re.search(pattern, query_lower)\n",
        "            if match:\n",
        "                company_name = match.group(1).strip()\n",
        "                print(f\"[DEBUG] STEP 3 (Company Name from pattern): {company_name}\")\n",
        "                # Check if this company name is in our mapping\n",
        "                if company_name in common_stocks:\n",
        "                    ticker = common_stocks[company_name]\n",
        "                    print(f\"[DEBUG] STEP 3 (Company Name) matched common stock '{company_name}', returning '{ticker}'\")\n",
        "                    _ticker_cache[cache_key] = ticker\n",
        "                    return ticker\n",
        "                break\n",
        "\n",
        "        # STEP 4: Detect exchange from query\n",
        "        exchange_suffix = detect_exchange(query_lower)\n",
        "        print(f\"[DEBUG] STEP 4 (Exchange Suffix): {exchange_suffix}\")\n",
        "\n",
        "        # STEP 5: Use web search with the extracted company name or full query\n",
        "        search_query = f\"{company_name or query} stock ticker symbol\"\n",
        "        print(f\"[DEBUG] STEP 5 (Web Search Query): {search_query}\")\n",
        "        try:\n",
        "            raw_search = search_tool.run(search_query)\n",
        "            print(f\"[DEBUG] STEP 5 (Raw Search Result): {raw_search[:200]}...\")\n",
        "        except:\n",
        "            raw_search = \"\"\n",
        "            print(\"[DEBUG] STEP 5 (Raw Search Result): Failed to get search results\")\n",
        "\n",
        "        # Look for ticker patterns in search results\n",
        "        # Be more careful - only match isolated tickers\n",
        "        potential_tickers = []\n",
        "\n",
        "        # Pattern 1: Hong Kong stocks (4 digits.HK)\n",
        "        hk_tickers = re.findall(r'\\b(\\d{4}\\.HK)\\b', raw_search, re.IGNORECASE)\n",
        "        potential_tickers.extend(hk_tickers)\n",
        "\n",
        "        # Pattern 2: Indian stocks (NAME.NS or NAME.BO)\n",
        "        indian_tickers = re.findall(r'\\b([A-Z][A-Z0-9&]{1,15}\\.(?:NS|BO))\\b', raw_search)\n",
        "        potential_tickers.extend(indian_tickers)\n",
        "\n",
        "        # Pattern 3: Standard US tickers (isolated 2-5 letter words)\n",
        "        # Only if preceded/followed by space or punctuation\n",
        "        us_tickers = re.findall(r'(?:^|\\s|:)([A-Z]{2,5})(?:\\s|$|,|\\.|:)', raw_search)\n",
        "\n",
        "        # Filter out common English words\n",
        "        english_words = {\n",
        "            'THE', 'AND', 'FOR', 'ARE', 'BUT', 'NOT', 'YOU', 'ALL', 'CAN',\n",
        "            'HER', 'WAS', 'ONE', 'OUR', 'OUT', 'DAY', 'GET', 'HAS', 'HIM',\n",
        "            'HIS', 'HOW', 'ITS', 'MAY', 'NEW', 'NOW', 'OLD', 'SEE', 'TWO',\n",
        "            'WAY', 'WHO', 'BOY', 'DID', 'LET', 'PUT', 'SAY', 'SHE', 'TOO',\n",
        "            'USE', 'OVER', 'SUCH', 'ONLY', 'THAN', 'FIND', 'VERY', 'JUST',\n",
        "            'STOCK', 'PRICE', 'MARKET', 'TRADE', 'SHARE', 'INDIA', 'CHINA',\n",
        "            'KONG', 'HONG', 'TREND', 'NEWS', 'TRIES', 'TRIES'  # Add problematic ones\n",
        "        }\n",
        "\n",
        "        for ticker in us_tickers:\n",
        "            if ticker not in english_words:\n",
        "                potential_tickers.append(ticker)\n",
        "        print(f\"[DEBUG] STEP 5 (Potential Tickers from search): {potential_tickers}\")\n",
        "\n",
        "        # Validate each potential ticker\n",
        "        for pticker in potential_tickers:\n",
        "            validated = validate_ticker(pticker)\n",
        "            if validated:\n",
        "                print(f\"[DEBUG] STEP 5 (Search Ticker) validated: {validated}\")\n",
        "                _ticker_cache[cache_key] = validated\n",
        "                return validated\n",
        "\n",
        "        # STEP 6: Try intelligent LLM extraction with strict format\n",
        "        if company_name or raw_search:\n",
        "            llm_prompt = f\"\"\"You are a stock ticker extraction system.\n",
        "\n",
        "Query: \"{query}\"\n",
        "Company detected: {company_name or 'Unknown'}\n",
        "Search results: {raw_search[:600]}\n",
        "\n",
        "Task: Extract ONLY the stock ticker symbol.\n",
        "\n",
        "Rules:\n",
        "- Indian stocks: Use format SYMBOL.NS (e.g., RELIANCE.NS, TCS.NS, INFY.NS)\n",
        "- Hong Kong: Use format ####.HK (e.g., 9988.HK)\n",
        "- US stocks: Just the symbol (e.g., AAPL, TSLA)\n",
        "- Return ONLY the ticker, nothing else\n",
        "- If uncertain, return UNKNOWN\n",
        "\n",
        "Ticker:\"\"\"\n",
        "\n",
        "            try:\n",
        "                print(f\"[DEBUG] STEP 6 (LLM Prompt): {llm_prompt[:200]}...\")\n",
        "                llm_response = local_llm.invoke(llm_prompt).strip().upper()\n",
        "                print(f\"[DEBUG] STEP 6 (LLM Response): {llm_response}\")\n",
        "                # Extract just the ticker from the response\n",
        "                ticker_match = re.search(r'\\b([A-Z0-9&]+(?:\\.[A-Z]{2})?)\\b', llm_response)\n",
        "                if ticker_match:\n",
        "                    llm_ticker = ticker_match.group(1)\n",
        "                    if llm_ticker != \"UNKNOWN\":\n",
        "                        validated = validate_ticker(llm_ticker)\n",
        "                        if validated:\n",
        "                            print(f\"[DEBUG] STEP 6 (LLM Ticker) validated: {validated}\")\n",
        "                            _ticker_cache[cache_key] = validated\n",
        "                            return validated\n",
        "            except Exception as e:\n",
        "                print(f\"[DEBUG] STEP 6 (LLM Error): {e}\")\n",
        "                pass\n",
        "\n",
        "        # STEP 7: Last resort - try the company name directly with yfinance\n",
        "        if company_name:\n",
        "            # Try with .NS suffix for Indian companies\n",
        "            if 'india' in query_lower or exchange_suffix == '.NS':\n",
        "                test_ticker = company_name.upper().replace(' ', '') + '.NS'\n",
        "                print(f\"[DEBUG] STEP 7 (Company Name + .NS): {test_ticker}\")\n",
        "                validated = validate_ticker(test_ticker)\n",
        "                if validated:\n",
        "                    print(f\"[DEBUG] STEP 7 (Company Name + .NS) validated: {validated}\")\n",
        "                    _ticker_cache[cache_key] = validated\n",
        "                    return validated\n",
        "\n",
        "        print(\"[DEBUG] TickerExtractor returning UNKNOWN\")\n",
        "        return \"UNKNOWN\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"[Ticker Extraction Error] {e}\")\n",
        "        return \"UNKNOWN\""
      ],
      "metadata": {
        "id": "m6uMuxA1cHXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommender_node(state: AgentState) -> AgentState:\n",
        "  sentiment = state.get('sentiment_score', 0.0)\n",
        "  if sentiment > 0.3:\n",
        "      rec = \"BUY - Positive sentiment and news momentum suggest upward potential.\"\n",
        "  elif sentiment < -0.3:\n",
        "      rec = \"SELL - Negative sentiment and news indicate downward pressure.\"\n",
        "  else:\n",
        "      rec = \"HOLD - Mixed or neutral signals suggest waiting for clearer trends.\"\n",
        "\n",
        "  state['recommendation'] = rec\n",
        "  state['messages'].append(f\"[Recommender] Recommendation: {rec.split('-')[0].strip()}\")\n",
        "  return state"
      ],
      "metadata": {
        "id": "jA4x9yqNg7gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(text):\n",
        "    return re.sub(r\"[^a-z0-9]\", \"\", text.lower())\n",
        "\n",
        "\n",
        "def company_matches(query: str, info: dict) -> bool:\n",
        "    if not info:\n",
        "        return False\n",
        "\n",
        "    q = normalize(query)\n",
        "\n",
        "    names = [\n",
        "        info.get(\"longName\", \"\"),\n",
        "        info.get(\"shortName\", \"\"),\n",
        "        info.get(\"symbol\", \"\")\n",
        "    ]\n",
        "\n",
        "    for name in names:\n",
        "        if normalize(name) in q or q in normalize(name):\n",
        "            return True\n",
        "\n",
        "    return False\n",
        "\n",
        "\n",
        "def has_price_data(symbol: str) -> bool:\n",
        "    try:\n",
        "        hist = yf.Ticker(symbol).history(period=\"5d\")\n",
        "        return hist is not None and not hist.empty\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "\n",
        "def global_stock_resolver(state: AgentState):\n",
        "    query = state[\"query\"]\n",
        "    messages = state.get(\"messages\", [])\n",
        "\n",
        "    messages.append(f\"[Resolver] Analyzing query: '{query}'\")\n",
        "\n",
        "    # Extract company name from conversational queries\n",
        "    # e.g., \"is alibaba stock falling\" -> \"alibaba\"\n",
        "    company_keywords = re.findall(r'\\b([a-zA-Z]+(?:\\s+[a-zA-Z]+)?)\\s+stock\\b', query.lower())\n",
        "\n",
        "    if company_keywords:\n",
        "        company_name = company_keywords[0]\n",
        "        messages.append(f\"[Resolver] Detected company: {company_name}\")\n",
        "        resolved_ticker = ticker_extractor(company_name)\n",
        "    else:\n",
        "        resolved_ticker = ticker_extractor(query)\n",
        "\n",
        "    if resolved_ticker == \"UNKNOWN\":\n",
        "        messages.append(\"[Resolver] âŒ Could not identify stock. Try: 'Alibaba Hong Kong' or 'BABA' or '9988.HK'\")\n",
        "    else:\n",
        "        messages.append(f\"[Resolver] âœ… Found ticker: {resolved_ticker}\")\n",
        "\n",
        "    return lock_ticker(state, resolved_ticker, \"GlobalResearcher\")"
      ],
      "metadata": {
        "id": "sUSFFiNKBMpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_financial_agent(query: str):\n",
        "    # 1. Initialize the Graph with your AgentState\n",
        "    workflow = StateGraph(AgentState)\n",
        "\n",
        "    # 2. Add ALL nodes (including the new Global Researcher)\n",
        "    workflow.add_node(\"global_researcher\", global_stock_resolver) # The New Node\n",
        "    workflow.add_node(\"intent\", intent_classifier)\n",
        "    workflow.add_node(\"data\", data_fetcher_node)\n",
        "    workflow.add_node(\"news\", news_researcher_node)\n",
        "    workflow.add_node(\"analyst\", analyst_node)\n",
        "    workflow.add_node(\"recommender\", recommender_node)\n",
        "\n",
        "    # 3. Define the Flow\n",
        "    # NEW ENTRY POINT: Start with Global Research to fix the ticker first\n",
        "    workflow.add_edge(START, \"global_researcher\")\n",
        "\n",
        "    # Connect the rest in a robust sequence\n",
        "    workflow.add_edge(\"global_researcher\", \"intent\")\n",
        "    workflow.add_edge(\"intent\", \"data\")\n",
        "    workflow.add_edge(\"data\", \"news\")\n",
        "    workflow.add_edge(\"news\", \"analyst\")\n",
        "    workflow.add_edge(\"analyst\", \"recommender\")\n",
        "    workflow.add_edge(\"recommender\", END)\n",
        "\n",
        "    # 4. Compile the final app\n",
        "    return workflow.compile()"
      ],
      "metadata": {
        "id": "XfoiwTabcaU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_stock_report(state: dict):\n",
        "    \"\"\"\n",
        "    Final formatting layer with correct currency support\n",
        "    \"\"\"\n",
        "    # 1. CLEAN DATA TYPES\n",
        "    def safe_num(val, format_str=\"{:,.2f}\"):\n",
        "        if val is None or (isinstance(val, (int, float, np.number)) and np.isnan(val)):\n",
        "            return \"N/A\"\n",
        "        try:\n",
        "            num = float(val)\n",
        "            return format_str.format(num)\n",
        "        except:\n",
        "            return \"N/A\"\n",
        "\n",
        "    pd = state.get('price_data', {})\n",
        "    ticker = state.get('ticker', 'UNKNOWN')\n",
        "    company = pd.get('company_name', 'Unknown Entity')\n",
        "\n",
        "    # GET CORRECT CURRENCY\n",
        "    currency_symbol, currency_code = get_currency_info(ticker, pd)\n",
        "\n",
        "    # 2. FIX ANALYSIS REPETITION\n",
        "    analysis = state.get('analysis', 'No analysis generated.')\n",
        "    sentences = analysis.split('.')\n",
        "    unique_sentences = []\n",
        "    for s in sentences:\n",
        "        s = s.strip()\n",
        "        if s and s not in unique_sentences:\n",
        "            unique_sentences.append(s)\n",
        "    clean_analysis = \". \".join(unique_sentences[:3]) + \".\"\n",
        "\n",
        "    # 3. CONSTRUCT MARKDOWN WITH CORRECT CURRENCY\n",
        "    report_md = f\"\"\"\n",
        "# ðŸ“ˆ Market Report: {company} ({ticker})\n",
        "**Currency:** {currency_code} ({currency_symbol})\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ“Š Key Performance Metrics\n",
        "| Metric | Value | Metric | Value |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| **Current Price** | `{currency_symbol}{safe_num(pd.get('current_price'))}` | **Market Cap** | `{currency_symbol}{safe_num(pd.get('market_cap'), \"{:,.0f}\")}` |\n",
        "| **Prev. Close** | `{currency_symbol}{safe_num(pd.get('previous_close'))}` | **P/E Ratio** | `{safe_num(pd.get('pe_ratio'))}` |\n",
        "| **50-Day Avg** | `{currency_symbol}{safe_num(pd.get('50_day_average'))}` | **Div. Yield** | `{safe_num(pd.get('dividend_yield'), \"{:.2%}\")}` |\n",
        "| **200-Day Avg** | `{currency_symbol}{safe_num(pd.get('200_day_average'))}` | **Target (Mean)** | `{currency_symbol}{safe_num(pd.get('target_mean_price'))}` |\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ§  AI Analysis & Recommendation\n",
        "**Sentiment Score:** `{state.get('sentiment_score', 0.0):.2f}`\n",
        "\n",
        "> **ANALYSIS:** {clean_analysis}\n",
        ">\n",
        "> **RECOMMENDATION:** **{state.get('recommendation', 'N/A')}**\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ“° Top News Headlines\n",
        "\"\"\"\n",
        "    # 4. FIX KEYERROR FOR NEWS\n",
        "    news = state.get('news_articles', [])[:10]\n",
        "    if not news:\n",
        "        report_md += \"_No recent news articles found for this symbol._\"\n",
        "    else:\n",
        "        for a in news:\n",
        "            url = a.get('url') or a.get('link') or \"#\"\n",
        "            source = a.get('media') or a.get('publisher', {}).get('title') or \"News\"\n",
        "            report_md += f\"* **{source}**: [{a.get('title')}]({url})\\n\"\n",
        "\n",
        "    display(Markdown(report_md))"
      ],
      "metadata": {
        "id": "svH2rlNeyNKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_currency_info(ticker: str, info: dict = None) -> tuple:\n",
        "    \"\"\"\n",
        "    Returns (currency_symbol, currency_code) for a given ticker\n",
        "    \"\"\"\n",
        "    # Exchange-based currency mapping\n",
        "    exchange_currency = {\n",
        "    # =========================\n",
        "    # ðŸ‡®ðŸ‡³ India\n",
        "    # =========================\n",
        "    '.NS': ('â‚¹', 'INR'),    # NSE (National Stock Exchange)\n",
        "    '.BO': ('â‚¹', 'INR'),    # BSE (Bombay Stock Exchange)\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡­ðŸ‡° Hong Kong\n",
        "    # =========================\n",
        "    '.HK': ('HK$', 'HKD'),  # Hong Kong Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¬ðŸ‡§ United Kingdom\n",
        "    # =========================\n",
        "    '.L': ('Â£', 'GBP'),     # London Stock Exchange (LSE)\n",
        "    '.IL': ('Â£', 'GBP'),    # London International\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¯ðŸ‡µ Japan\n",
        "    # =========================\n",
        "    '.T': ('Â¥', 'JPY'),     # Tokyo Stock Exchange\n",
        "    '.OS': ('Â¥', 'JPY'),    # Osaka Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¦ðŸ‡º Australia\n",
        "    # =========================\n",
        "    '.AX': ('A$', 'AUD'),   # Australian Securities Exchange (ASX)\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¨ðŸ‡¦ Canada\n",
        "    # =========================\n",
        "    '.TO': ('C$', 'CAD'),   # Toronto Stock Exchange (TSX)\n",
        "    '.V': ('C$', 'CAD'),    # TSX Venture Exchange\n",
        "    '.CN': ('C$', 'CAD'),   # Canadian Securities Exchange (CSE)\n",
        "    '.NE': ('C$', 'CAD'),   # NEO Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡ºðŸ‡¸ USA\n",
        "    # =========================\n",
        "    '': ('$', 'USD'),       # Default (no suffix) - typically NYSE/NASDAQ\n",
        "    '.N': ('$', 'USD'),     # NYSE\n",
        "    '.O': ('$', 'USD'),     # NASDAQ\n",
        "    '.A': ('$', 'USD'),     # NYSE American (formerly AMEX)\n",
        "    '.OQ': ('$', 'USD'),    # NASDAQ Global Select\n",
        "    '.NQ': ('$', 'USD'),    # NASDAQ\n",
        "    '.K': ('$', 'USD'),     # BATS Global Markets\n",
        "    '.PK': ('$', 'USD'),    # OTC Pink Sheets\n",
        "    '.OB': ('$', 'USD'),    # OTC Bulletin Board\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡§ðŸ‡· Brazil\n",
        "    # =========================\n",
        "    '.SA': ('R$', 'BRL'),   # B3 (Brasil Bolsa BalcÃ£o) - SÃ£o Paulo\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡«ðŸ‡· France\n",
        "    # =========================\n",
        "    '.PA': ('â‚¬', 'EUR'),    # Euronext Paris\n",
        "    '.NX': ('â‚¬', 'EUR'),    # Euronext\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡©ðŸ‡ª Germany\n",
        "    # =========================\n",
        "    '.DE': ('â‚¬', 'EUR'),    # XETRA (Frankfurt)\n",
        "    '.F': ('â‚¬', 'EUR'),     # Frankfurt Stock Exchange\n",
        "    '.BE': ('â‚¬', 'EUR'),    # Berlin\n",
        "    '.DU': ('â‚¬', 'EUR'),    # DÃ¼sseldorf\n",
        "    '.HM': ('â‚¬', 'EUR'),    # Hamburg\n",
        "    '.HA': ('â‚¬', 'EUR'),    # Hanover\n",
        "    '.MU': ('â‚¬', 'EUR'),    # Munich\n",
        "    '.SG': ('â‚¬', 'EUR'),    # Stuttgart\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¨ðŸ‡­ Switzerland\n",
        "    # =========================\n",
        "    '.SW': ('CHF', 'CHF'),  # SIX Swiss Exchange\n",
        "    '.VX': ('CHF', 'CHF'),  # SIX (alternative suffix)\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡°ðŸ‡· South Korea\n",
        "    # =========================\n",
        "    '.KS': ('â‚©', 'KRW'),    # Korea Stock Exchange (KOSPI)\n",
        "    '.KQ': ('â‚©', 'KRW'),    # KOSDAQ\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¨ðŸ‡³ China\n",
        "    # =========================\n",
        "    '.SS': ('Â¥', 'CNY'),    # Shanghai Stock Exchange\n",
        "    '.SZ': ('Â¥', 'CNY'),    # Shenzhen Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¹ðŸ‡¼ Taiwan\n",
        "    # =========================\n",
        "    '.TW': ('NT$', 'TWD'),  # Taiwan Stock Exchange\n",
        "    '.TWO': ('NT$', 'TWD'), # Taipei Exchange (OTC)\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¸ðŸ‡¬ Singapore\n",
        "    # =========================\n",
        "    '.SI': ('S$', 'SGD'),   # Singapore Exchange (SGX)\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡®ðŸ‡© Indonesia\n",
        "    # =========================\n",
        "    '.JK': ('Rp', 'IDR'),   # Indonesia Stock Exchange (IDX)\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡²ðŸ‡¾ Malaysia\n",
        "    # =========================\n",
        "    '.KL': ('RM', 'MYR'),   # Bursa Malaysia\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¹ðŸ‡­ Thailand\n",
        "    # =========================\n",
        "    '.BK': ('à¸¿', 'THB'),    # Stock Exchange of Thailand (SET)\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡µðŸ‡­ Philippines\n",
        "    # =========================\n",
        "    '.PS': ('â‚±', 'PHP'),    # Philippine Stock Exchange (PSE)\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡»ðŸ‡³ Vietnam\n",
        "    # =========================\n",
        "    '.VN': ('â‚«', 'VND'),    # Ho Chi Minh Stock Exchange\n",
        "    '.HN': ('â‚«', 'VND'),    # Hanoi Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡³ðŸ‡± Netherlands\n",
        "    # =========================\n",
        "    '.AS': ('â‚¬', 'EUR'),    # Euronext Amsterdam\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡§ðŸ‡ª Belgium\n",
        "    # =========================\n",
        "    '.BR': ('â‚¬', 'EUR'),    # Euronext Brussels\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡µðŸ‡¹ Portugal\n",
        "    # =========================\n",
        "    '.LS': ('â‚¬', 'EUR'),    # Euronext Lisbon\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡®ðŸ‡ª Ireland\n",
        "    # =========================\n",
        "    '.IR': ('â‚¬', 'EUR'),    # Euronext Dublin (Irish Stock Exchange)\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡ªðŸ‡¸ Spain\n",
        "    # =========================\n",
        "    '.MC': ('â‚¬', 'EUR'),    # Bolsa de Madrid\n",
        "    '.BA': ('â‚¬', 'EUR'),    # Barcelona (BME Spanish Exchanges)\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡®ðŸ‡¹ Italy\n",
        "    # =========================\n",
        "    '.MI': ('â‚¬', 'EUR'),    # Borsa Italiana (Milan)\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¦ðŸ‡¹ Austria\n",
        "    # =========================\n",
        "    '.VI': ('â‚¬', 'EUR'),    # Vienna Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¬ðŸ‡· Greece\n",
        "    # =========================\n",
        "    '.AT': ('â‚¬', 'EUR'),    # Athens Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡©ðŸ‡° Denmark\n",
        "    # =========================\n",
        "    '.CO': ('kr', 'DKK'),   # Nasdaq Copenhagen\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¸ðŸ‡ª Sweden\n",
        "    # =========================\n",
        "    '.ST': ('kr', 'SEK'),   # Nasdaq Stockholm\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡³ðŸ‡´ Norway\n",
        "    # =========================\n",
        "    '.OL': ('kr', 'NOK'),   # Oslo BÃ¸rs\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡«ðŸ‡® Finland\n",
        "    # =========================\n",
        "    '.HE': ('â‚¬', 'EUR'),    # Nasdaq Helsinki\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡®ðŸ‡¸ Iceland\n",
        "    # =========================\n",
        "    '.IC': ('kr', 'ISK'),   # Nasdaq Iceland\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡µðŸ‡± Poland\n",
        "    # =========================\n",
        "    '.WA': ('zÅ‚', 'PLN'),   # Warsaw Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¨ðŸ‡¿ Czech Republic\n",
        "    # =========================\n",
        "    '.PR': ('KÄ', 'CZK'),   # Prague Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡­ðŸ‡º Hungary\n",
        "    # =========================\n",
        "    '.BD': ('Ft', 'HUF'),   # Budapest Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡·ðŸ‡´ Romania\n",
        "    # =========================\n",
        "    '.RO': ('lei', 'RON'),  # Bucharest Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡§ðŸ‡¬ Bulgaria\n",
        "    # =========================\n",
        "    '.SO': ('Ð»Ð²', 'BGN'),   # Bulgarian Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡­ðŸ‡· Croatia\n",
        "    # =========================\n",
        "    '.ZA': ('kn', 'HRK'),   # Zagreb Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡·ðŸ‡¸ Serbia\n",
        "    # =========================\n",
        "    '.BG': ('Ð´Ð¸Ð½', 'RSD'),  # Belgrade Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¹ðŸ‡· Turkey\n",
        "    # =========================\n",
        "    '.IS': ('â‚º', 'TRY'),    # Borsa Istanbul\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡²ðŸ‡½ Mexico\n",
        "    # =========================\n",
        "    '.MX': ('$', 'MXN'),    # Bolsa Mexicana de Valores\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¦ðŸ‡· Argentina\n",
        "    # =========================\n",
        "    '.BA': ('$', 'ARS'),    # Buenos Aires Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¨ðŸ‡± Chile\n",
        "    # =========================\n",
        "    '.SN': ('$', 'CLP'),    # Santiago Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¨ðŸ‡´ Colombia\n",
        "    # =========================\n",
        "    '.CO': ('$', 'COP'),    # Colombia Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡µðŸ‡ª Peru\n",
        "    # =========================\n",
        "    '.LM': ('S/', 'PEN'),   # Lima Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡»ðŸ‡ª Venezuela\n",
        "    # =========================\n",
        "    '.CR': ('Bs', 'VES'),   # Caracas Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡®ðŸ‡± Israel\n",
        "    # =========================\n",
        "    '.TA': ('â‚ª', 'ILS'),    # Tel Aviv Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¸ðŸ‡¦ Saudi Arabia\n",
        "    # =========================\n",
        "    '.SR': ('ï·¼', 'SAR'),    # Saudi Stock Exchange (Tadawul)\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¶ðŸ‡¦ Qatar\n",
        "    # =========================\n",
        "    '.QA': ('ï·¼', 'QAR'),    # Qatar Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡°ðŸ‡¼ Kuwait\n",
        "    # =========================\n",
        "    '.KW': ('Ø¯.Ùƒ', 'KWD'),  # Boursa Kuwait\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¦ðŸ‡ª United Arab Emirates\n",
        "    # =========================\n",
        "    '.AD': ('Ø¯.Ø¥', 'AED'),  # Abu Dhabi Securities Exchange\n",
        "    '.DU': ('Ø¯.Ø¥', 'AED'),  # Dubai Financial Market\n",
        "    '.DF': ('Ø¯.Ø¥', 'AED'),  # Nasdaq Dubai\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡´ðŸ‡² Oman\n",
        "    # =========================\n",
        "    '.MS': ('ï·¼', 'OMR'),    # Muscat Securities Market\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡§ðŸ‡­ Bahrain\n",
        "    # =========================\n",
        "    '.BH': ('Ø¯.Ø¨', 'BHD'),  # Bahrain Bourse\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¯ðŸ‡´ Jordan\n",
        "    # =========================\n",
        "    '.AM': ('Ø¯.Ø§', 'JOD'),  # Amman Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡±ðŸ‡§ Lebanon\n",
        "    # =========================\n",
        "    '.BY': ('Ù„.Ù„', 'LBP'),  # Beirut Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡ªðŸ‡¬ Egypt\n",
        "    # =========================\n",
        "    '.CA': ('EÂ£', 'EGP'),   # Egyptian Exchange (Cairo)\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡²ðŸ‡¦ Morocco\n",
        "    # =========================\n",
        "    '.CS': ('Ø¯.Ù….', 'MAD'), # Casablanca Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¹ðŸ‡³ Tunisia\n",
        "    # =========================\n",
        "    '.TU': ('Ø¯.Øª', 'TND'),  # Tunis Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡³ðŸ‡¬ Nigeria\n",
        "    # =========================\n",
        "    '.LG': ('â‚¦', 'NGN'),    # Nigerian Stock Exchange (Lagos)\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡°ðŸ‡ª Kenya\n",
        "    # =========================\n",
        "    '.NR': ('KSh', 'KES'),  # Nairobi Securities Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¿ðŸ‡¦ South Africa\n",
        "    # =========================\n",
        "    '.JO': ('R', 'ZAR'),    # Johannesburg Stock Exchange (JSE)\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¿ðŸ‡¼ Zimbabwe\n",
        "    # =========================\n",
        "    '.ZW': ('$', 'ZWL'),    # Zimbabwe Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡§ðŸ‡¼ Botswana\n",
        "    # =========================\n",
        "    '.BT': ('P', 'BWP'),    # Botswana Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡²ðŸ‡º Mauritius\n",
        "    # =========================\n",
        "    '.MU': ('â‚¨', 'MUR'),    # Stock Exchange of Mauritius\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¬ðŸ‡­ Ghana\n",
        "    # =========================\n",
        "    '.GH': ('â‚µ', 'GHS'),    # Ghana Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡ºðŸ‡¬ Uganda\n",
        "    # =========================\n",
        "    '.UG': ('USh', 'UGX'),  # Uganda Securities Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¹ðŸ‡¿ Tanzania\n",
        "    # =========================\n",
        "    '.TZ': ('TSh', 'TZS'),  # Dar es Salaam Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡·ðŸ‡º Russia\n",
        "    # =========================\n",
        "    '.ME': ('â‚½', 'RUB'),    # Moscow Exchange (limited trading)\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡ºðŸ‡¦ Ukraine\n",
        "    # =========================\n",
        "    '.UX': ('â‚´', 'UAH'),    # Ukrainian Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡°ðŸ‡¿ Kazakhstan\n",
        "    # =========================\n",
        "    '.KZ': ('â‚¸', 'KZT'),    # Kazakhstan Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡µðŸ‡° Pakistan\n",
        "    # =========================\n",
        "    '.KA': ('â‚¨', 'PKR'),    # Karachi Stock Exchange\n",
        "    '.IS': ('â‚¨', 'PKR'),    # Islamabad Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡§ðŸ‡© Bangladesh\n",
        "    # =========================\n",
        "    '.DH': ('à§³', 'BDT'),    # Dhaka Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡±ðŸ‡° Sri Lanka\n",
        "    # =========================\n",
        "    '.CM': ('Rs', 'LKR'),   # Colombo Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡³ðŸ‡µ Nepal\n",
        "    # =========================\n",
        "    '.NP': ('à¤°à¥‚', 'NPR'),   # Nepal Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡³ðŸ‡¿ New Zealand\n",
        "    # =========================\n",
        "    '.NZ': ('NZ$', 'NZD'),  # New Zealand Exchange (NZX)\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡µðŸ‡¬ Papua New Guinea\n",
        "    # =========================\n",
        "    '.PG': ('K', 'PGK'),    # Port Moresby Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡«ðŸ‡¯ Fiji\n",
        "    # =========================\n",
        "    '.SPX': ('FJ$', 'FJD'), # South Pacific Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¦ðŸ‡² Armenia\n",
        "    # =========================\n",
        "    '.AM': ('Ö', 'AMD'),    # Armenian Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¬ðŸ‡ª Georgia\n",
        "    # =========================\n",
        "    '.GE': ('â‚¾', 'GEL'),    # Georgian Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¦ðŸ‡¿ Azerbaijan\n",
        "    # =========================\n",
        "    '.AZ': ('â‚¼', 'AZN'),    # Baku Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡²ðŸ‡³ Mongolia\n",
        "    # =========================\n",
        "    '.MN': ('â‚®', 'MNT'),    # Mongolian Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡°ðŸ‡­ Cambodia\n",
        "    # =========================\n",
        "    '.KH': ('áŸ›', 'KHR'),    # Cambodia Securities Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡±ðŸ‡¦ Laos\n",
        "    # =========================\n",
        "    '.LA': ('â‚­', 'LAK'),    # Lao Securities Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡²ðŸ‡² Myanmar\n",
        "    # =========================\n",
        "    '.MM': ('K', 'MMK'),    # Yangon Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡§ðŸ‡³ Brunei\n",
        "    # =========================\n",
        "    '.BN': ('B$', 'BND'),   # Brunei Stock Exchange (planned)\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¯ðŸ‡² Jamaica\n",
        "    # =========================\n",
        "    '.JM': ('J$', 'JMD'),   # Jamaica Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¹ðŸ‡¹ Trinidad and Tobago\n",
        "    # =========================\n",
        "    '.TT': ('TT$', 'TTD'),  # Trinidad and Tobago Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡§ðŸ‡§ Barbados\n",
        "    # =========================\n",
        "    '.BB': ('Bds$', 'BBD'), # Barbados Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡§ðŸ‡¸ Bahamas\n",
        "    # =========================\n",
        "    '.BS': ('B$', 'BSD'),   # Bahamas International Securities Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¨ðŸ‡· Costa Rica\n",
        "    # =========================\n",
        "    '.CR': ('â‚¡', 'CRC'),    # Costa Rica Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡µðŸ‡¦ Panama\n",
        "    # =========================\n",
        "    '.PA': ('B/.', 'PAB'),  # Panama Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡§ðŸ‡´ Bolivia\n",
        "    # =========================\n",
        "    '.BO': ('Bs', 'BOB'),   # Bolivian Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡ªðŸ‡¨ Ecuador\n",
        "    # =========================\n",
        "    '.EC': ('$', 'USD'),    # Quito & Guayaquil Stock Exchanges\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡ºðŸ‡¾ Uruguay\n",
        "    # =========================\n",
        "    '.MV': ('$U', 'UYU'),   # Montevideo Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡µðŸ‡¾ Paraguay\n",
        "    # =========================\n",
        "    '.PY': ('â‚²', 'PYG'),    # AsunciÃ³n Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡±ðŸ‡º Luxembourg\n",
        "    # =========================\n",
        "    '.LU': ('â‚¬', 'EUR'),    # Luxembourg Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡²ðŸ‡¹ Malta\n",
        "    # =========================\n",
        "    '.MT': ('â‚¬', 'EUR'),    # Malta Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¨ðŸ‡¾ Cyprus\n",
        "    # =========================\n",
        "    '.CY': ('â‚¬', 'EUR'),    # Cyprus Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡ªðŸ‡ª Estonia\n",
        "    # =========================\n",
        "    '.TL': ('â‚¬', 'EUR'),    # Nasdaq Tallinn\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡±ðŸ‡» Latvia\n",
        "    # =========================\n",
        "    '.RG': ('â‚¬', 'EUR'),    # Nasdaq Riga\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡±ðŸ‡¹ Lithuania\n",
        "    # =========================\n",
        "    '.VS': ('â‚¬', 'EUR'),    # Nasdaq Vilnius\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¸ðŸ‡® Slovenia\n",
        "    # =========================\n",
        "    '.LJ': ('â‚¬', 'EUR'),    # Ljubljana Stock Exchange\n",
        "\n",
        "    # =========================\n",
        "    # ðŸ‡¸ðŸ‡° Slovakia\n",
        "    # =========================\n",
        "    '.BTS': ('â‚¬', 'EUR'),   # Bratislava Stock Exchange\n",
        "}\n",
        "\n",
        "\n",
        "    # Check ticker suffix first\n",
        "    for suffix, (symbol, code) in exchange_currency.items():\n",
        "        if ticker.endswith(suffix):\n",
        "            return (symbol, code)\n",
        "\n",
        "    # Fallback: Try to get from yfinance info\n",
        "    if info:\n",
        "        currency_code = info.get('currency', 'USD')\n",
        "        currency_symbols = {\n",
        "            'INR': 'â‚¹', 'USD': '$', 'EUR': 'â‚¬', 'GBP': 'Â£',\n",
        "            'JPY': 'Â¥', 'CNY': 'Â¥', 'HKD': 'HK$', 'AUD': 'A$',\n",
        "            'CAD': 'C$', 'CHF': 'CHF', 'KRW': 'â‚©', 'BRL': 'R$'\n",
        "        }\n",
        "        symbol = currency_symbols.get(currency_code, currency_code + ' ')\n",
        "        return (symbol, currency_code)\n",
        "\n",
        "    # Default to USD\n",
        "    return ('$', 'USD')"
      ],
      "metadata": {
        "id": "_1PiNuRJxx2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_chatbot(query: str):\n",
        "  agent=create_financial_agent(query)\n",
        "  initial_state=AgentState(\n",
        "      query=query,\n",
        "      ticker=\"\",\n",
        "      intent=\"\",\n",
        "      price_data={},\n",
        "      financial_data={},\n",
        "      news_articles=[],\n",
        "      news_context=[],\n",
        "      sentiment_score=0.0,\n",
        "      analysis=\"\",\n",
        "      recommendation=\"\",\n",
        "      messages=[]\n",
        "  )\n",
        "  result = agent.invoke(initial_state)\n",
        "  result=format_stock_report(result)\n",
        "  return result"
      ],
      "metadata": {
        "id": "Hz3LeMrnN7y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e8dce8e"
      },
      "source": [
        "run_chatbot(\"what is the situation of mahindra in india\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}